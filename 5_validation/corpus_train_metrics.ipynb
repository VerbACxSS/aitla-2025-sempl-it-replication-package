{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr9yWJNLIx6_"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tSDf1n7iIJo_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sets(sets):\n",
    "  merged = set()\n",
    "  for s in sets:\n",
    "    merged = merged.union(s)\n",
    "  return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvcgTTzMtJre"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTS = ['text', 'proofreading_text', 'lex_text', 'connectives_text', 'expressions_text', 'sentence_splitter_text', 'nominalizations_text', 'verbs_text', 'sentence_reorganizer_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1716393383660,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "hiRDCeoejAQB",
    "outputId": "cc48f935-f71a-4b58-e4a6-a7d43e084826"
   },
   "outputs": [],
   "source": [
    "metrics_dfs = {TEXT:[] for TEXT in TEXTS}\n",
    "raw_data = {TEXT:[] for TEXT in TEXTS}\n",
    "\n",
    "for TEXT in TEXTS:\n",
    "    metrics_dfs[TEXT] = pd.read_csv(f'./metrics/corpus_train/{TEXT}_metrics.csv')\n",
    "    raw_data[TEXT] = json.load(open(f'./metrics/corpus_train/{TEXT}_raw_data.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens (con punteg.)</th>\n",
       "      <th>Caratteri</th>\n",
       "      <th>Caratteri (con punt)</th>\n",
       "      <th>Sillabe</th>\n",
       "      <th>Frasi</th>\n",
       "      <th>Types</th>\n",
       "      <th>Lemmi</th>\n",
       "      <th>Tokens per frase</th>\n",
       "      <th>Tokens per paragrafo</th>\n",
       "      <th>Frasi per paragrafo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>298955</td>\n",
       "      <td>337869</td>\n",
       "      <td>1731081</td>\n",
       "      <td>1770071</td>\n",
       "      <td>719576</td>\n",
       "      <td>11185</td>\n",
       "      <td>18483</td>\n",
       "      <td>13478</td>\n",
       "      <td>26.728207</td>\n",
       "      <td>293.093137</td>\n",
       "      <td>10.965686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>299841</td>\n",
       "      <td>343928</td>\n",
       "      <td>1735367</td>\n",
       "      <td>1779520</td>\n",
       "      <td>721692</td>\n",
       "      <td>11806</td>\n",
       "      <td>17987</td>\n",
       "      <td>13022</td>\n",
       "      <td>25.397340</td>\n",
       "      <td>293.961765</td>\n",
       "      <td>11.574510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>298309</td>\n",
       "      <td>342109</td>\n",
       "      <td>1731138</td>\n",
       "      <td>1775004</td>\n",
       "      <td>718393</td>\n",
       "      <td>11887</td>\n",
       "      <td>17967</td>\n",
       "      <td>13009</td>\n",
       "      <td>25.095398</td>\n",
       "      <td>292.459804</td>\n",
       "      <td>11.653922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>293866</td>\n",
       "      <td>337370</td>\n",
       "      <td>1709162</td>\n",
       "      <td>1752732</td>\n",
       "      <td>708869</td>\n",
       "      <td>11825</td>\n",
       "      <td>17765</td>\n",
       "      <td>12856</td>\n",
       "      <td>24.851247</td>\n",
       "      <td>288.103922</td>\n",
       "      <td>11.593137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>260410</td>\n",
       "      <td>301186</td>\n",
       "      <td>1513287</td>\n",
       "      <td>1554127</td>\n",
       "      <td>628319</td>\n",
       "      <td>11828</td>\n",
       "      <td>15968</td>\n",
       "      <td>11617</td>\n",
       "      <td>22.016402</td>\n",
       "      <td>255.303922</td>\n",
       "      <td>11.596078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>268622</td>\n",
       "      <td>310818</td>\n",
       "      <td>1563990</td>\n",
       "      <td>1606248</td>\n",
       "      <td>649634</td>\n",
       "      <td>15964</td>\n",
       "      <td>16091</td>\n",
       "      <td>11713</td>\n",
       "      <td>16.826735</td>\n",
       "      <td>263.354902</td>\n",
       "      <td>15.650980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>267334</td>\n",
       "      <td>309525</td>\n",
       "      <td>1552643</td>\n",
       "      <td>1594895</td>\n",
       "      <td>646854</td>\n",
       "      <td>15959</td>\n",
       "      <td>16598</td>\n",
       "      <td>11997</td>\n",
       "      <td>16.751300</td>\n",
       "      <td>262.092157</td>\n",
       "      <td>15.646078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>269516</td>\n",
       "      <td>311857</td>\n",
       "      <td>1566499</td>\n",
       "      <td>1608899</td>\n",
       "      <td>651025</td>\n",
       "      <td>15948</td>\n",
       "      <td>16743</td>\n",
       "      <td>12089</td>\n",
       "      <td>16.899674</td>\n",
       "      <td>264.231373</td>\n",
       "      <td>15.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>271345</td>\n",
       "      <td>312987</td>\n",
       "      <td>1576724</td>\n",
       "      <td>1618428</td>\n",
       "      <td>655350</td>\n",
       "      <td>15829</td>\n",
       "      <td>16653</td>\n",
       "      <td>12005</td>\n",
       "      <td>17.142271</td>\n",
       "      <td>266.024510</td>\n",
       "      <td>15.518627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Tokens  Tokens (con punteg.)  Caratteri  \\\n",
       "0                       text  298955                337869    1731081   \n",
       "1          proofreading_text  299841                343928    1735367   \n",
       "2                   lex_text  298309                342109    1731138   \n",
       "3           connectives_text  293866                337370    1709162   \n",
       "4           expressions_text  260410                301186    1513287   \n",
       "5     sentence_splitter_text  268622                310818    1563990   \n",
       "6       nominalizations_text  267334                309525    1552643   \n",
       "7                 verbs_text  269516                311857    1566499   \n",
       "8  sentence_reorganizer_text  271345                312987    1576724   \n",
       "\n",
       "   Caratteri (con punt)  Sillabe  Frasi  Types  Lemmi  Tokens per frase  \\\n",
       "0               1770071   719576  11185  18483  13478         26.728207   \n",
       "1               1779520   721692  11806  17987  13022         25.397340   \n",
       "2               1775004   718393  11887  17967  13009         25.095398   \n",
       "3               1752732   708869  11825  17765  12856         24.851247   \n",
       "4               1554127   628319  11828  15968  11617         22.016402   \n",
       "5               1606248   649634  15964  16091  11713         16.826735   \n",
       "6               1594895   646854  15959  16598  11997         16.751300   \n",
       "7               1608899   651025  15948  16743  12089         16.899674   \n",
       "8               1618428   655350  15829  16653  12005         17.142271   \n",
       "\n",
       "   Tokens per paragrafo  Frasi per paragrafo  \n",
       "0            293.093137            10.965686  \n",
       "1            293.961765            11.574510  \n",
       "2            292.459804            11.653922  \n",
       "3            288.103922            11.593137  \n",
       "4            255.303922            11.596078  \n",
       "5            263.354902            15.650980  \n",
       "6            262.092157            15.646078  \n",
       "7            264.231373            15.635294  \n",
       "8            266.024510            15.518627  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':               TEXT,\n",
    "    'Tokens':               df['n_tokens'].sum(),\n",
    "    'Tokens (con punteg.)': df['n_tokens_all'].sum(),\n",
    "    'Caratteri':            df['n_chars'].sum(),\n",
    "    'Caratteri (con punt)': df['n_chars_all'].sum(),\n",
    "    'Sillabe':              df['n_syllables'].sum(),\n",
    "    'Frasi':                df['n_sentences'].sum(),\n",
    "    'Types':                len(merge_sets([set(j['tokens']) for j in raw_data[TEXT]])),\n",
    "    'Lemmi':                len(merge_sets([set(j['lemmas']) for j in raw_data[TEXT]])),\n",
    "    'Tokens per frase':     df['n_tokens'].sum() / df['n_sentences'].sum(),\n",
    "    'Tokens per paragrafo': df['n_tokens'].sum() / df.shape[0],\n",
    "    'Frasi per paragrafo':  df['n_sentences'].sum() / df.shape[0],\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coord.</th>\n",
       "      <th>Cong. sub.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>242</td>\n",
       "      <td>90639</td>\n",
       "      <td>30839</td>\n",
       "      <td>7019</td>\n",
       "      <td>460</td>\n",
       "      <td>7507</td>\n",
       "      <td>28559</td>\n",
       "      <td>6424</td>\n",
       "      <td>0</td>\n",
       "      <td>34545</td>\n",
       "      <td>68718</td>\n",
       "      <td>9325</td>\n",
       "      <td>38393</td>\n",
       "      <td>0</td>\n",
       "      <td>13756</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>238</td>\n",
       "      <td>90624</td>\n",
       "      <td>30819</td>\n",
       "      <td>7153</td>\n",
       "      <td>470</td>\n",
       "      <td>7447</td>\n",
       "      <td>29060</td>\n",
       "      <td>6313</td>\n",
       "      <td>0</td>\n",
       "      <td>34575</td>\n",
       "      <td>69080</td>\n",
       "      <td>9292</td>\n",
       "      <td>43544</td>\n",
       "      <td>0</td>\n",
       "      <td>13888</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>240</td>\n",
       "      <td>89774</td>\n",
       "      <td>30798</td>\n",
       "      <td>6662</td>\n",
       "      <td>471</td>\n",
       "      <td>7447</td>\n",
       "      <td>29058</td>\n",
       "      <td>6310</td>\n",
       "      <td>0</td>\n",
       "      <td>34507</td>\n",
       "      <td>68921</td>\n",
       "      <td>9267</td>\n",
       "      <td>43337</td>\n",
       "      <td>0</td>\n",
       "      <td>13892</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>226</td>\n",
       "      <td>87026</td>\n",
       "      <td>31875</td>\n",
       "      <td>6644</td>\n",
       "      <td>468</td>\n",
       "      <td>7621</td>\n",
       "      <td>30078</td>\n",
       "      <td>6259</td>\n",
       "      <td>0</td>\n",
       "      <td>34293</td>\n",
       "      <td>65359</td>\n",
       "      <td>9216</td>\n",
       "      <td>43045</td>\n",
       "      <td>0</td>\n",
       "      <td>13585</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>189</td>\n",
       "      <td>77211</td>\n",
       "      <td>29973</td>\n",
       "      <td>6471</td>\n",
       "      <td>469</td>\n",
       "      <td>6004</td>\n",
       "      <td>28225</td>\n",
       "      <td>4536</td>\n",
       "      <td>0</td>\n",
       "      <td>30460</td>\n",
       "      <td>54294</td>\n",
       "      <td>8831</td>\n",
       "      <td>40286</td>\n",
       "      <td>2</td>\n",
       "      <td>12641</td>\n",
       "      <td>1594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>188</td>\n",
       "      <td>79041</td>\n",
       "      <td>33532</td>\n",
       "      <td>6470</td>\n",
       "      <td>468</td>\n",
       "      <td>6614</td>\n",
       "      <td>30272</td>\n",
       "      <td>5296</td>\n",
       "      <td>0</td>\n",
       "      <td>30847</td>\n",
       "      <td>54035</td>\n",
       "      <td>8921</td>\n",
       "      <td>41673</td>\n",
       "      <td>2</td>\n",
       "      <td>11992</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>185</td>\n",
       "      <td>73840</td>\n",
       "      <td>39408</td>\n",
       "      <td>6468</td>\n",
       "      <td>469</td>\n",
       "      <td>7291</td>\n",
       "      <td>31009</td>\n",
       "      <td>6058</td>\n",
       "      <td>0</td>\n",
       "      <td>30169</td>\n",
       "      <td>50097</td>\n",
       "      <td>8908</td>\n",
       "      <td>41669</td>\n",
       "      <td>2</td>\n",
       "      <td>12002</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>184</td>\n",
       "      <td>76598</td>\n",
       "      <td>35856</td>\n",
       "      <td>6471</td>\n",
       "      <td>466</td>\n",
       "      <td>7160</td>\n",
       "      <td>35043</td>\n",
       "      <td>7208</td>\n",
       "      <td>0</td>\n",
       "      <td>29890</td>\n",
       "      <td>47817</td>\n",
       "      <td>8980</td>\n",
       "      <td>41820</td>\n",
       "      <td>2</td>\n",
       "      <td>12164</td>\n",
       "      <td>2197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>182</td>\n",
       "      <td>77564</td>\n",
       "      <td>35790</td>\n",
       "      <td>6464</td>\n",
       "      <td>467</td>\n",
       "      <td>7170</td>\n",
       "      <td>36083</td>\n",
       "      <td>6885</td>\n",
       "      <td>0</td>\n",
       "      <td>29956</td>\n",
       "      <td>47854</td>\n",
       "      <td>9066</td>\n",
       "      <td>41122</td>\n",
       "      <td>3</td>\n",
       "      <td>12209</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Altro   Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                       text    242  90639  30839    7019      460     7507   \n",
       "1          proofreading_text    238  90624  30819    7153      470     7447   \n",
       "2                   lex_text    240  89774  30798    6662      471     7447   \n",
       "3           connectives_text    226  87026  31875    6644      468     7621   \n",
       "4           expressions_text    189  77211  29973    6471      469     6004   \n",
       "5     sentence_splitter_text    188  79041  33532    6470      468     6614   \n",
       "6       nominalizations_text    185  73840  39408    6468      469     7291   \n",
       "7                 verbs_text    184  76598  35856    6471      466     7160   \n",
       "8  sentence_reorganizer_text    182  77564  35790    6464      467     7170   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0     28559     6424           0     34545         68718         9325   \n",
       "1     29060     6313           0     34575         69080         9292   \n",
       "2     29058     6310           0     34507         68921         9267   \n",
       "3     30078     6259           0     34293         65359         9216   \n",
       "4     28225     4536           0     30460         54294         8831   \n",
       "5     30272     5296           0     30847         54035         8921   \n",
       "6     31009     6058           0     30169         50097         8908   \n",
       "7     35043     7208           0     29890         47817         8980   \n",
       "8     36083     6885           0     29956         47854         9066   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coord.  Cong. sub.  \n",
       "0          38393             0         13756        1442  \n",
       "1          43544             0         13888        1425  \n",
       "2          43337             0         13892        1425  \n",
       "3          43045             0         13585        1675  \n",
       "4          40286             2         12641        1594  \n",
       "5          41673             2         11992        1467  \n",
       "6          41669             2         12002        1950  \n",
       "7          41820             2         12164        2197  \n",
       "8          41122             3         12209        2171  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':        TEXT,\n",
    "    'Altro':         df['n_other'].sum(),\n",
    "    'Nomi':          df['n_nouns'].sum(),\n",
    "    'Verbi':         df['n_verbs'].sum(),\n",
    "    'Numeri':        df['n_number'].sum(),\n",
    "    'Simboli':       df['n_symbols'].sum(),\n",
    "    'Avverbi':       df['n_adverbs'].sum(),\n",
    "    'Articoli':      df['n_articles'].sum(),\n",
    "    'Pronomi':       df['n_pronouns'].sum(),\n",
    "    'Particelle':    df['n_particles'].sum(),\n",
    "    'Agettivi':      df['n_adjectives'].sum(),\n",
    "    'Preposizioni':  df['n_prepositions'].sum(),\n",
    "    'Nomi propri':   df['n_proper_nouns'].sum(),\n",
    "    'Punteggiatura': df['n_punctuations'].sum(),\n",
    "    'Interiezioni':  df['n_interjections'].sum(),\n",
    "    'Cong. coord.':  df['n_coordinating_conjunctions'].sum(),\n",
    "    'Cong. sub.':    df['n_subordinating_conjunctions'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coordinati</th>\n",
       "      <th>Cong. subordiante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>0.07</td>\n",
       "      <td>27.28</td>\n",
       "      <td>9.44</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.78</td>\n",
       "      <td>20.39</td>\n",
       "      <td>2.72</td>\n",
       "      <td>11.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>26.77</td>\n",
       "      <td>9.26</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.92</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.60</td>\n",
       "      <td>20.19</td>\n",
       "      <td>2.64</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>0.07</td>\n",
       "      <td>26.69</td>\n",
       "      <td>9.29</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.93</td>\n",
       "      <td>8.51</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.62</td>\n",
       "      <td>20.25</td>\n",
       "      <td>2.63</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>26.21</td>\n",
       "      <td>9.81</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.07</td>\n",
       "      <td>8.94</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.72</td>\n",
       "      <td>19.40</td>\n",
       "      <td>2.64</td>\n",
       "      <td>12.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>25.97</td>\n",
       "      <td>10.44</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.91</td>\n",
       "      <td>9.54</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>18.15</td>\n",
       "      <td>2.74</td>\n",
       "      <td>13.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>25.75</td>\n",
       "      <td>11.36</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.10</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.38</td>\n",
       "      <td>17.42</td>\n",
       "      <td>2.67</td>\n",
       "      <td>13.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>23.87</td>\n",
       "      <td>13.53</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.37</td>\n",
       "      <td>10.33</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>16.05</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>24.72</td>\n",
       "      <td>12.15</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.31</td>\n",
       "      <td>11.85</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.98</td>\n",
       "      <td>14.97</td>\n",
       "      <td>2.66</td>\n",
       "      <td>13.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>25.03</td>\n",
       "      <td>12.04</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.29</td>\n",
       "      <td>12.25</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>14.93</td>\n",
       "      <td>2.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Altro   Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                       text   0.07  27.28   9.44    1.94     0.11     1.99   \n",
       "1          proofreading_text   0.06  26.77   9.26    1.94     0.11     1.92   \n",
       "2                   lex_text   0.07  26.69   9.29    1.85     0.11     1.93   \n",
       "3           connectives_text   0.06  26.21   9.81    1.86     0.12     2.07   \n",
       "4           expressions_text   0.06  25.97  10.44    1.97     0.12     1.91   \n",
       "5     sentence_splitter_text   0.06  25.75  11.36    1.90     0.12     2.10   \n",
       "6       nominalizations_text   0.06  23.87  13.53    1.90     0.12     2.37   \n",
       "7                 verbs_text   0.06  24.72  12.15    1.88     0.11     2.31   \n",
       "8  sentence_reorganizer_text   0.06  25.03  12.04    1.87     0.11     2.29   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0      8.48     1.91         0.0      9.78         20.39         2.72   \n",
       "1      8.48     1.84         0.0      9.60         20.19         2.64   \n",
       "2      8.51     1.85         0.0      9.62         20.25         2.63   \n",
       "3      8.94     1.84         0.0      9.72         19.40         2.64   \n",
       "4      9.54     1.50         0.0      9.63         18.15         2.74   \n",
       "5     10.00     1.67         0.0      9.38         17.42         2.67   \n",
       "6     10.33     2.07         0.0      9.18         16.05         2.68   \n",
       "7     11.85     2.47         0.0      8.98         14.97         2.66   \n",
       "8     12.25     2.32         0.0      8.97         14.93         2.68   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coordinati  Cong. subordiante  \n",
       "0          11.31           0.0              4.17               0.42  \n",
       "1          12.67           0.0              4.12               0.41  \n",
       "2          12.67           0.0              4.13               0.41  \n",
       "3          12.77           0.0              4.09               0.49  \n",
       "4          13.16           0.0              4.25               0.56  \n",
       "5          13.24           0.0              3.85               0.49  \n",
       "6          13.28           0.0              3.87               0.69  \n",
       "7          13.16           0.0              3.92               0.77  \n",
       "8          12.76           0.0              3.92               0.76  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':              TEXT,\n",
    "    'Altro':               round((df['n_other'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi':                round((df['n_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Verbi':               round((df['n_verbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Numeri':              round((df['n_number'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Simboli':             round((df['n_symbols'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Avverbi':             round((df['n_adverbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Articoli':            round((df['n_articles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Pronomi':             round((df['n_pronouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Particelle':          round((df['n_particles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Agettivi':            round((df['n_adjectives'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Preposizioni':        round((df['n_prepositions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi propri':         round((df['n_proper_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Punteggiatura':       round((df['n_punctuations'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Interiezioni':        round((df['n_interjections'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. coordinati':    round((df['n_coordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. subordiante':   round((df['n_subordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>24500</td>\n",
       "      <td>6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>24426</td>\n",
       "      <td>6393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>24405</td>\n",
       "      <td>6393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>25518</td>\n",
       "      <td>6357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>24180</td>\n",
       "      <td>5793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>25978</td>\n",
       "      <td>7554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>32404</td>\n",
       "      <td>7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>33054</td>\n",
       "      <td>2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>33113</td>\n",
       "      <td>2677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Verbi attivi  Verbi passivi\n",
       "0                       text         24500           6339\n",
       "1          proofreading_text         24426           6393\n",
       "2                   lex_text         24405           6393\n",
       "3           connectives_text         25518           6357\n",
       "4           expressions_text         24180           5793\n",
       "5     sentence_splitter_text         25978           7554\n",
       "6       nominalizations_text         32404           7004\n",
       "7                 verbs_text         33054           2802\n",
       "8  sentence_reorganizer_text         33113           2677"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   df['n_active_verbs'].sum(),\n",
    "    'Verbi passivi':  df['n_passive_verbs'].sum()\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>80.30</td>\n",
       "      <td>19.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>80.12</td>\n",
       "      <td>19.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>80.11</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>81.06</td>\n",
       "      <td>18.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>81.57</td>\n",
       "      <td>18.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>77.48</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>82.67</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>92.91</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>93.37</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Verbi attivi  Verbi passivi\n",
       "0                       text         80.30          19.51\n",
       "1          proofreading_text         80.12          19.68\n",
       "2                   lex_text         80.11          19.69\n",
       "3           connectives_text         81.06          18.74\n",
       "4           expressions_text         81.57          18.34\n",
       "5     sentence_splitter_text         77.48          22.42\n",
       "6       nominalizations_text         82.67          17.33\n",
       "7                 verbs_text         92.91           6.99\n",
       "8  sentence_reorganizer_text         93.37           6.53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   round((df['n_active_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "    'Verbi passivi':  round((df['n_passive_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>216430</td>\n",
       "      <td>180317</td>\n",
       "      <td>37107</td>\n",
       "      <td>33712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>217105</td>\n",
       "      <td>180947</td>\n",
       "      <td>37171</td>\n",
       "      <td>33669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>216290</td>\n",
       "      <td>180194</td>\n",
       "      <td>37109</td>\n",
       "      <td>33650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>215236</td>\n",
       "      <td>180323</td>\n",
       "      <td>35533</td>\n",
       "      <td>32287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>193619</td>\n",
       "      <td>162363</td>\n",
       "      <td>31801</td>\n",
       "      <td>27188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>201459</td>\n",
       "      <td>169496</td>\n",
       "      <td>32556</td>\n",
       "      <td>26788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>203750</td>\n",
       "      <td>172671</td>\n",
       "      <td>31709</td>\n",
       "      <td>25966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>206514</td>\n",
       "      <td>174716</td>\n",
       "      <td>32429</td>\n",
       "      <td>25555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>208197</td>\n",
       "      <td>176078</td>\n",
       "      <td>32761</td>\n",
       "      <td>25606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus     ALL      FO     AU     AD\n",
       "0                       text  216430  180317  37107  33712\n",
       "1          proofreading_text  217105  180947  37171  33669\n",
       "2                   lex_text  216290  180194  37109  33650\n",
       "3           connectives_text  215236  180323  35533  32287\n",
       "4           expressions_text  193619  162363  31801  27188\n",
       "5     sentence_splitter_text  201459  169496  32556  26788\n",
       "6       nominalizations_text  203750  172671  31709  25966\n",
       "7                 verbs_text  206514  174716  32429  25555\n",
       "8  sentence_reorganizer_text  208197  176078  32761  25606"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'ALL':      df['n_vdb'].sum(),\n",
    "    'FO':       df['n_vdb_fo'].sum(),\n",
    "    'AU':       df['n_vdb_au'].sum(),\n",
    "    'AD':       df['n_vdb_ad'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>72.09</td>\n",
       "      <td>59.68</td>\n",
       "      <td>12.70</td>\n",
       "      <td>11.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>72.11</td>\n",
       "      <td>59.71</td>\n",
       "      <td>12.71</td>\n",
       "      <td>11.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>72.18</td>\n",
       "      <td>59.74</td>\n",
       "      <td>12.75</td>\n",
       "      <td>11.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>72.91</td>\n",
       "      <td>60.72</td>\n",
       "      <td>12.37</td>\n",
       "      <td>10.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>74.46</td>\n",
       "      <td>62.40</td>\n",
       "      <td>12.23</td>\n",
       "      <td>10.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>75.18</td>\n",
       "      <td>63.22</td>\n",
       "      <td>12.14</td>\n",
       "      <td>9.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>76.67</td>\n",
       "      <td>65.13</td>\n",
       "      <td>11.75</td>\n",
       "      <td>9.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>77.33</td>\n",
       "      <td>65.57</td>\n",
       "      <td>11.96</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>77.49</td>\n",
       "      <td>65.67</td>\n",
       "      <td>12.03</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ALL     FO     AU     AD\n",
       "0                       text  72.09  59.68  12.70  11.22\n",
       "1          proofreading_text  72.11  59.71  12.71  11.17\n",
       "2                   lex_text  72.18  59.74  12.75  11.21\n",
       "3           connectives_text  72.91  60.72  12.37  10.88\n",
       "4           expressions_text  74.46  62.40  12.23  10.47\n",
       "5     sentence_splitter_text  75.18  63.22  12.14   9.92\n",
       "6       nominalizations_text  76.67  65.13  11.75   9.61\n",
       "7                 verbs_text  77.33  65.57  11.96   9.35\n",
       "8  sentence_reorganizer_text  77.49  65.67  12.03   9.30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus': TEXT,\n",
    "    'ALL':    round((df['n_vdb'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'FO':     round((df['n_vdb_fo'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AU':     round((df['n_vdb_au'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AD':     round((df['n_vdb_ad'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>difficult_connectives</th>\n",
       "      <th>latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>3772</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>3854</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>3856</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>380</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>771</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>755</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>711</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>733</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>723</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  difficult_connectives  latinisms\n",
       "0                       text                   3772         23\n",
       "1          proofreading_text                   3854         23\n",
       "2                   lex_text                   3856         23\n",
       "3           connectives_text                    380         18\n",
       "4           expressions_text                    771          5\n",
       "5     sentence_splitter_text                    755          5\n",
       "6       nominalizations_text                    711          5\n",
       "7                 verbs_text                    733          5\n",
       "8  sentence_reorganizer_text                    723          5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'difficult_connectives':  df['n_difficult_connectives'].sum(),\n",
    "    'latinisms':              df['n_latinisms'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>unique_difficult_connectives</th>\n",
       "      <th>unique_latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>402</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>399</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>399</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>148</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  unique_difficult_connectives  unique_latinisms\n",
       "0                       text                           402                10\n",
       "1          proofreading_text                           399                10\n",
       "2                   lex_text                           399                10\n",
       "3           connectives_text                            81                 9\n",
       "4           expressions_text                           139                 4\n",
       "5     sentence_splitter_text                           148                 4\n",
       "6       nominalizations_text                           145                 4\n",
       "7                 verbs_text                           139                 4\n",
       "8  sentence_reorganizer_text                           138                 4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'unique_difficult_connectives': len(merge_sets([set(j['difficult_connectives']) for j in raw_data[TEXT]])),\n",
    "    'unique_latinisms':       len(merge_sets([set(j['latinisms']) for j in raw_data[TEXT]])),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ttr</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>flesch_vacca</th>\n",
       "      <th>lexical_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>65.41</td>\n",
       "      <td>42.73</td>\n",
       "      <td>19.05</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>65.10</td>\n",
       "      <td>43.61</td>\n",
       "      <td>20.52</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>65.09</td>\n",
       "      <td>43.63</td>\n",
       "      <td>20.90</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>65.52</td>\n",
       "      <td>43.65</td>\n",
       "      <td>20.80</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>66.74</td>\n",
       "      <td>45.01</td>\n",
       "      <td>23.76</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>66.64</td>\n",
       "      <td>49.43</td>\n",
       "      <td>31.02</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>67.22</td>\n",
       "      <td>49.76</td>\n",
       "      <td>31.06</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>66.04</td>\n",
       "      <td>49.47</td>\n",
       "      <td>31.43</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>65.15</td>\n",
       "      <td>49.11</td>\n",
       "      <td>31.11</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ttr  gulpease_index  flesch_vacca  \\\n",
       "0                       text  65.41           42.73         19.05   \n",
       "1          proofreading_text  65.10           43.61         20.52   \n",
       "2                   lex_text  65.09           43.63         20.90   \n",
       "3           connectives_text  65.52           43.65         20.80   \n",
       "4           expressions_text  66.74           45.01         23.76   \n",
       "5     sentence_splitter_text  66.64           49.43         31.02   \n",
       "6       nominalizations_text  67.22           49.76         31.06   \n",
       "7                 verbs_text  66.04           49.47         31.43   \n",
       "8  sentence_reorganizer_text  65.15           49.11         31.11   \n",
       "\n",
       "   lexical_density  \n",
       "0             0.55  \n",
       "1             0.55  \n",
       "2             0.54  \n",
       "3             0.55  \n",
       "4             0.55  \n",
       "5             0.56  \n",
       "6             0.57  \n",
       "7             0.56  \n",
       "8             0.55  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':             TEXT,\n",
    "    'ttr':                round(df['ttr'].mean(), 2),\n",
    "    'gulpease_index':     round(df['gulpease'].mean(), 2),\n",
    "    'flesch_vacca':       round(df['flesch_vacca'].mean(), 2),\n",
    "    'lexical_density':    round(df['lexical_density'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>99.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>99.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>99.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>98.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>98.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>98.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>97.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>97.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  semantic_similarity\n",
       "0          original vs proofreading_text                99.63\n",
       "1                   original vs lex_text                99.52\n",
       "2           original vs connectives_text                99.37\n",
       "3           original vs expressions_text                98.50\n",
       "4     original vs sentence_splitter_text                98.35\n",
       "5       original vs nominalizations_text                98.18\n",
       "6                 original vs verbs_text                97.90\n",
       "7  original vs sentence_reorganizer_text                97.82"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':               f'original vs {TEXT}',\n",
    "    'semantic_similarity':  round(df['semantic_similarity'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>%_added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "      <th>%_deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>29057</td>\n",
       "      <td>4448</td>\n",
       "      <td>2657</td>\n",
       "      <td>59.73</td>\n",
       "      <td>5302</td>\n",
       "      <td>2953</td>\n",
       "      <td>55.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>41762</td>\n",
       "      <td>5910</td>\n",
       "      <td>3097</td>\n",
       "      <td>52.40</td>\n",
       "      <td>7917</td>\n",
       "      <td>3988</td>\n",
       "      <td>50.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>105146</td>\n",
       "      <td>11959</td>\n",
       "      <td>8377</td>\n",
       "      <td>70.05</td>\n",
       "      <td>16740</td>\n",
       "      <td>10333</td>\n",
       "      <td>61.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>446859</td>\n",
       "      <td>31682</td>\n",
       "      <td>24821</td>\n",
       "      <td>78.34</td>\n",
       "      <td>52697</td>\n",
       "      <td>36400</td>\n",
       "      <td>69.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>496369</td>\n",
       "      <td>39141</td>\n",
       "      <td>31798</td>\n",
       "      <td>81.24</td>\n",
       "      <td>53324</td>\n",
       "      <td>36814</td>\n",
       "      <td>69.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>550938</td>\n",
       "      <td>47403</td>\n",
       "      <td>38223</td>\n",
       "      <td>80.63</td>\n",
       "      <td>60851</td>\n",
       "      <td>41332</td>\n",
       "      <td>67.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>614708</td>\n",
       "      <td>51958</td>\n",
       "      <td>42542</td>\n",
       "      <td>81.88</td>\n",
       "      <td>66055</td>\n",
       "      <td>45643</td>\n",
       "      <td>69.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>656257</td>\n",
       "      <td>52215</td>\n",
       "      <td>42901</td>\n",
       "      <td>82.16</td>\n",
       "      <td>66290</td>\n",
       "      <td>45834</td>\n",
       "      <td>69.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading_text         29057          4448   \n",
       "1                   original vs lex_text         41762          5910   \n",
       "2           original vs connectives_text        105146         11959   \n",
       "3           original vs expressions_text        446859         31682   \n",
       "4     original vs sentence_splitter_text        496369         39141   \n",
       "5       original vs nominalizations_text        550938         47403   \n",
       "6                 original vs verbs_text        614708         51958   \n",
       "7  original vs sentence_reorganizer_text        656257         52215   \n",
       "\n",
       "   added_vdb_tokens  %_added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \\\n",
       "0              2657               59.73            5302                2953   \n",
       "1              3097               52.40            7917                3988   \n",
       "2              8377               70.05           16740               10333   \n",
       "3             24821               78.34           52697               36400   \n",
       "4             31798               81.24           53324               36814   \n",
       "5             38223               80.63           60851               41332   \n",
       "6             42542               81.88           66055               45643   \n",
       "7             42901               82.16           66290               45834   \n",
       "\n",
       "   %_deleted_vdb_tokens  \n",
       "0                 55.70  \n",
       "1                 50.37  \n",
       "2                 61.73  \n",
       "3                 69.07  \n",
       "4                 69.04  \n",
       "5                 67.92  \n",
       "6                 69.10  \n",
       "7                 69.14  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':                 f'original vs {TEXT}',\n",
    "    'editdistance':           df['editdistance'].sum(),\n",
    "    'added_tokens':           df['n_added_tokens'].sum(),\n",
    "    'added_vdb_tokens':       df['n_added_vdb_tokens'].sum(),\n",
    "    '%_added_vdb_tokens':     round(df['n_added_vdb_tokens'].sum() / df['n_added_tokens'].sum() * 100, 2),\n",
    "    'deleted_tokens':         df['n_deleted_tokens'].sum(),\n",
    "    'deleted_vdb_tokens':     df['n_deleted_vdb_tokens'].sum(),\n",
    "    '%_deleted_vdb_tokens':   round(df['n_deleted_vdb_tokens'].sum() / df['n_deleted_tokens'].sum() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.53</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>6.64</td>\n",
       "      <td>5.65</td>\n",
       "      <td>3.93</td>\n",
       "      <td>11.16</td>\n",
       "      <td>7.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>23.41</td>\n",
       "      <td>14.83</td>\n",
       "      <td>11.64</td>\n",
       "      <td>28.68</td>\n",
       "      <td>20.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>27.06</td>\n",
       "      <td>17.54</td>\n",
       "      <td>14.28</td>\n",
       "      <td>21.30</td>\n",
       "      <td>14.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>30.98</td>\n",
       "      <td>21.66</td>\n",
       "      <td>17.64</td>\n",
       "      <td>25.25</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>35.44</td>\n",
       "      <td>23.64</td>\n",
       "      <td>19.62</td>\n",
       "      <td>27.22</td>\n",
       "      <td>18.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>38.28</td>\n",
       "      <td>23.52</td>\n",
       "      <td>19.60</td>\n",
       "      <td>26.97</td>\n",
       "      <td>18.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading_text          2.04          2.11   \n",
       "1                   original vs lex_text          2.86          2.73   \n",
       "2           original vs connectives_text          6.64          5.65   \n",
       "3           original vs expressions_text         23.41         14.83   \n",
       "4     original vs sentence_splitter_text         27.06         17.54   \n",
       "5       original vs nominalizations_text         30.98         21.66   \n",
       "6                 original vs verbs_text         35.44         23.64   \n",
       "7  original vs sentence_reorganizer_text         38.28         23.52   \n",
       "\n",
       "   added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \n",
       "0              1.31            2.22                1.29  \n",
       "1              1.53            3.23                1.70  \n",
       "2              3.93           11.16                7.48  \n",
       "3             11.64           28.68               20.04  \n",
       "4             14.28           21.30               14.55  \n",
       "5             17.64           25.25               16.88  \n",
       "6             19.62           27.22               18.54  \n",
       "7             19.60           26.97               18.38  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':             f'original vs {TEXT}',\n",
    "    'editdistance':       round((df['editdistance'] / pd.concat([metrics_dfs['text']['n_chars'], df['n_chars']], axis=1).max(axis=1)).mean() * 100, 2),\n",
    "    'added_tokens':       round((df['n_added_tokens'] / df['n_tokens']).mean() * 100, 2),\n",
    "    'added_vdb_tokens':   round((df['n_added_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_tokens':     round((df['n_deleted_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_vdb_tokens': round((df['n_deleted_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
