{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr9yWJNLIx6_"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tSDf1n7iIJo_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sets(sets):\n",
    "  merged = set()\n",
    "  for s in sets:\n",
    "    merged = merged.union(s)\n",
    "  return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvcgTTzMtJre"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTS = ['text', 'proofreading_text', 'lex_text', 'connectives_text', 'expressions_text', 'sentence_splitter_text', 'nominalizations_text', 'verbs_text', 'sentence_reorganizer_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1716393383660,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "hiRDCeoejAQB",
    "outputId": "cc48f935-f71a-4b58-e4a6-a7d43e084826"
   },
   "outputs": [],
   "source": [
    "metrics_dfs = {TEXT:[] for TEXT in TEXTS}\n",
    "raw_data = {TEXT:[] for TEXT in TEXTS}\n",
    "\n",
    "for TEXT in TEXTS:\n",
    "    metrics_dfs[TEXT] = pd.read_csv(f'./metrics/corpus_val/{TEXT}_metrics.csv')\n",
    "    raw_data[TEXT] = json.load(open(f'./metrics/corpus_val/{TEXT}_raw_data.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens (con punteg.)</th>\n",
       "      <th>Caratteri</th>\n",
       "      <th>Caratteri (con punt)</th>\n",
       "      <th>Sillabe</th>\n",
       "      <th>Frasi</th>\n",
       "      <th>Types</th>\n",
       "      <th>Lemmi</th>\n",
       "      <th>Tokens per frase</th>\n",
       "      <th>Tokens per paragrafo</th>\n",
       "      <th>Frasi per paragrafo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>18778</td>\n",
       "      <td>21356</td>\n",
       "      <td>109508</td>\n",
       "      <td>112091</td>\n",
       "      <td>45310</td>\n",
       "      <td>704</td>\n",
       "      <td>4223</td>\n",
       "      <td>3104</td>\n",
       "      <td>26.673295</td>\n",
       "      <td>329.438596</td>\n",
       "      <td>12.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>18862</td>\n",
       "      <td>21767</td>\n",
       "      <td>109787</td>\n",
       "      <td>112697</td>\n",
       "      <td>45458</td>\n",
       "      <td>768</td>\n",
       "      <td>4189</td>\n",
       "      <td>3068</td>\n",
       "      <td>24.559896</td>\n",
       "      <td>330.912281</td>\n",
       "      <td>13.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>18772</td>\n",
       "      <td>21652</td>\n",
       "      <td>109415</td>\n",
       "      <td>112300</td>\n",
       "      <td>45242</td>\n",
       "      <td>773</td>\n",
       "      <td>4169</td>\n",
       "      <td>3051</td>\n",
       "      <td>24.284605</td>\n",
       "      <td>329.333333</td>\n",
       "      <td>13.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>18615</td>\n",
       "      <td>21487</td>\n",
       "      <td>108498</td>\n",
       "      <td>111375</td>\n",
       "      <td>44860</td>\n",
       "      <td>770</td>\n",
       "      <td>4136</td>\n",
       "      <td>3025</td>\n",
       "      <td>24.175325</td>\n",
       "      <td>326.578947</td>\n",
       "      <td>13.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>16286</td>\n",
       "      <td>18996</td>\n",
       "      <td>94796</td>\n",
       "      <td>97512</td>\n",
       "      <td>39225</td>\n",
       "      <td>790</td>\n",
       "      <td>3765</td>\n",
       "      <td>2775</td>\n",
       "      <td>20.615190</td>\n",
       "      <td>285.719298</td>\n",
       "      <td>13.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>16697</td>\n",
       "      <td>19503</td>\n",
       "      <td>97494</td>\n",
       "      <td>100306</td>\n",
       "      <td>40374</td>\n",
       "      <td>1046</td>\n",
       "      <td>3817</td>\n",
       "      <td>2795</td>\n",
       "      <td>15.962715</td>\n",
       "      <td>292.929825</td>\n",
       "      <td>18.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>16552</td>\n",
       "      <td>19350</td>\n",
       "      <td>96542</td>\n",
       "      <td>99346</td>\n",
       "      <td>40095</td>\n",
       "      <td>1045</td>\n",
       "      <td>3877</td>\n",
       "      <td>2823</td>\n",
       "      <td>15.839234</td>\n",
       "      <td>290.385965</td>\n",
       "      <td>18.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>16703</td>\n",
       "      <td>19503</td>\n",
       "      <td>97485</td>\n",
       "      <td>100291</td>\n",
       "      <td>40393</td>\n",
       "      <td>1036</td>\n",
       "      <td>3891</td>\n",
       "      <td>2820</td>\n",
       "      <td>16.122587</td>\n",
       "      <td>293.035088</td>\n",
       "      <td>18.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>16825</td>\n",
       "      <td>19598</td>\n",
       "      <td>98155</td>\n",
       "      <td>100935</td>\n",
       "      <td>40677</td>\n",
       "      <td>1032</td>\n",
       "      <td>3880</td>\n",
       "      <td>2813</td>\n",
       "      <td>16.303295</td>\n",
       "      <td>295.175439</td>\n",
       "      <td>18.105263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Tokens  Tokens (con punteg.)  Caratteri  \\\n",
       "0                       text   18778                 21356     109508   \n",
       "1          proofreading_text   18862                 21767     109787   \n",
       "2                   lex_text   18772                 21652     109415   \n",
       "3           connectives_text   18615                 21487     108498   \n",
       "4           expressions_text   16286                 18996      94796   \n",
       "5     sentence_splitter_text   16697                 19503      97494   \n",
       "6       nominalizations_text   16552                 19350      96542   \n",
       "7                 verbs_text   16703                 19503      97485   \n",
       "8  sentence_reorganizer_text   16825                 19598      98155   \n",
       "\n",
       "   Caratteri (con punt)  Sillabe  Frasi  Types  Lemmi  Tokens per frase  \\\n",
       "0                112091    45310    704   4223   3104         26.673295   \n",
       "1                112697    45458    768   4189   3068         24.559896   \n",
       "2                112300    45242    773   4169   3051         24.284605   \n",
       "3                111375    44860    770   4136   3025         24.175325   \n",
       "4                 97512    39225    790   3765   2775         20.615190   \n",
       "5                100306    40374   1046   3817   2795         15.962715   \n",
       "6                 99346    40095   1045   3877   2823         15.839234   \n",
       "7                100291    40393   1036   3891   2820         16.122587   \n",
       "8                100935    40677   1032   3880   2813         16.303295   \n",
       "\n",
       "   Tokens per paragrafo  Frasi per paragrafo  \n",
       "0            329.438596            12.350877  \n",
       "1            330.912281            13.473684  \n",
       "2            329.333333            13.561404  \n",
       "3            326.578947            13.508772  \n",
       "4            285.719298            13.859649  \n",
       "5            292.929825            18.350877  \n",
       "6            290.385965            18.333333  \n",
       "7            293.035088            18.175439  \n",
       "8            295.175439            18.105263  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':               TEXT,\n",
    "    'Tokens':               df['n_tokens'].sum(),\n",
    "    'Tokens (con punteg.)': df['n_tokens_all'].sum(),\n",
    "    'Caratteri':            df[f'n_chars'].sum(),\n",
    "    'Caratteri (con punt)': df['n_chars_all'].sum(),\n",
    "    'Sillabe':              df['n_syllables'].sum(),\n",
    "    'Frasi':                df['n_sentences'].sum(),\n",
    "    'Types':                len(merge_sets([set(j['tokens']) for j in raw_data[TEXT]])),\n",
    "    'Lemmi':                len(merge_sets([set(j['lemmas']) for j in raw_data[TEXT]])),\n",
    "    'Tokens per frase':     df['n_tokens'].sum() / df['n_sentences'].sum(),\n",
    "    'Tokens per paragrafo': df['n_tokens'].sum() / df.shape[0],\n",
    "    'Frasi per paragrafo':  df['n_sentences'].sum() / df.shape[0],\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coord.</th>\n",
       "      <th>Cong. sub.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>16</td>\n",
       "      <td>5694</td>\n",
       "      <td>1823</td>\n",
       "      <td>440</td>\n",
       "      <td>55</td>\n",
       "      <td>475</td>\n",
       "      <td>1688</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>2286</td>\n",
       "      <td>4385</td>\n",
       "      <td>603</td>\n",
       "      <td>2526</td>\n",
       "      <td>0</td>\n",
       "      <td>915</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>19</td>\n",
       "      <td>5697</td>\n",
       "      <td>1807</td>\n",
       "      <td>448</td>\n",
       "      <td>49</td>\n",
       "      <td>473</td>\n",
       "      <td>1709</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>2296</td>\n",
       "      <td>4434</td>\n",
       "      <td>619</td>\n",
       "      <td>2854</td>\n",
       "      <td>0</td>\n",
       "      <td>922</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>18</td>\n",
       "      <td>5646</td>\n",
       "      <td>1806</td>\n",
       "      <td>427</td>\n",
       "      <td>49</td>\n",
       "      <td>473</td>\n",
       "      <td>1708</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>2288</td>\n",
       "      <td>4420</td>\n",
       "      <td>626</td>\n",
       "      <td>2831</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>17</td>\n",
       "      <td>5513</td>\n",
       "      <td>1881</td>\n",
       "      <td>427</td>\n",
       "      <td>49</td>\n",
       "      <td>500</td>\n",
       "      <td>1787</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>2278</td>\n",
       "      <td>4226</td>\n",
       "      <td>628</td>\n",
       "      <td>2823</td>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>17</td>\n",
       "      <td>4787</td>\n",
       "      <td>1772</td>\n",
       "      <td>434</td>\n",
       "      <td>51</td>\n",
       "      <td>393</td>\n",
       "      <td>1676</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>3434</td>\n",
       "      <td>606</td>\n",
       "      <td>2646</td>\n",
       "      <td>0</td>\n",
       "      <td>838</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>16</td>\n",
       "      <td>4901</td>\n",
       "      <td>1968</td>\n",
       "      <td>435</td>\n",
       "      <td>51</td>\n",
       "      <td>430</td>\n",
       "      <td>1810</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>3383</td>\n",
       "      <td>612</td>\n",
       "      <td>2739</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>16</td>\n",
       "      <td>4578</td>\n",
       "      <td>2304</td>\n",
       "      <td>436</td>\n",
       "      <td>51</td>\n",
       "      <td>470</td>\n",
       "      <td>1860</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>1964</td>\n",
       "      <td>3143</td>\n",
       "      <td>609</td>\n",
       "      <td>2731</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>16</td>\n",
       "      <td>4703</td>\n",
       "      <td>2124</td>\n",
       "      <td>436</td>\n",
       "      <td>50</td>\n",
       "      <td>471</td>\n",
       "      <td>2061</td>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>3012</td>\n",
       "      <td>614</td>\n",
       "      <td>2733</td>\n",
       "      <td>0</td>\n",
       "      <td>803</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>15</td>\n",
       "      <td>4761</td>\n",
       "      <td>2123</td>\n",
       "      <td>436</td>\n",
       "      <td>50</td>\n",
       "      <td>467</td>\n",
       "      <td>2124</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>1949</td>\n",
       "      <td>3014</td>\n",
       "      <td>622</td>\n",
       "      <td>2706</td>\n",
       "      <td>0</td>\n",
       "      <td>806</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Altro  Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                       text     16  5694   1823     440       55      475   \n",
       "1          proofreading_text     19  5697   1807     448       49      473   \n",
       "2                   lex_text     18  5646   1806     427       49      473   \n",
       "3           connectives_text     17  5513   1881     427       49      500   \n",
       "4           expressions_text     17  4787   1772     434       51      393   \n",
       "5     sentence_splitter_text     16  4901   1968     435       51      430   \n",
       "6       nominalizations_text     16  4578   2304     436       51      470   \n",
       "7                 verbs_text     16  4703   2124     436       50      471   \n",
       "8  sentence_reorganizer_text     15  4761   2123     436       50      467   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0      1688      378           0      2286          4385          603   \n",
       "1      1709      374           0      2296          4434          619   \n",
       "2      1708      374           0      2288          4420          626   \n",
       "3      1787      374           0      2278          4226          628   \n",
       "4      1676      276           0      1995          3434          606   \n",
       "5      1810      285           0      2009          3383          612   \n",
       "6      1860      311           0      1964          3143          609   \n",
       "7      2061      433           0      1946          3012          614   \n",
       "8      2124      427           0      1949          3014          622   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coord.  Cong. sub.  \n",
       "0           2526             0           915          72  \n",
       "1           2854             0           922          66  \n",
       "2           2831             0           920          66  \n",
       "3           2823             0           898          86  \n",
       "4           2646             0           838          71  \n",
       "5           2739             0           799          65  \n",
       "6           2731             0           799          78  \n",
       "7           2733             0           803         101  \n",
       "8           2706             0           806          98  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':        TEXT,\n",
    "    'Altro':         df['n_other'].sum(),\n",
    "    'Nomi':          df['n_nouns'].sum(),\n",
    "    'Verbi':         df['n_verbs'].sum(),\n",
    "    'Numeri':        df['n_number'].sum(),\n",
    "    'Simboli':       df['n_symbols'].sum(),\n",
    "    'Avverbi':       df['n_adverbs'].sum(),\n",
    "    'Articoli':      df['n_articles'].sum(),\n",
    "    'Pronomi':       df['n_pronouns'].sum(),\n",
    "    'Particelle':    df['n_particles'].sum(),\n",
    "    'Agettivi':      df['n_adjectives'].sum(),\n",
    "    'Preposizioni':  df['n_prepositions'].sum(),\n",
    "    'Nomi propri':   df['n_proper_nouns'].sum(),\n",
    "    'Punteggiatura': df['n_punctuations'].sum(),\n",
    "    'Interiezioni':  df['n_interjections'].sum(),\n",
    "    'Cong. coord.':  df['n_coordinating_conjunctions'].sum(),\n",
    "    'Cong. sub.':    df['n_subordinating_conjunctions'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coordinati</th>\n",
       "      <th>Cong. subordiante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>27.73</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.17</td>\n",
       "      <td>20.40</td>\n",
       "      <td>2.27</td>\n",
       "      <td>12.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>0.09</td>\n",
       "      <td>27.16</td>\n",
       "      <td>8.81</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.01</td>\n",
       "      <td>7.55</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>20.33</td>\n",
       "      <td>2.31</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>0.07</td>\n",
       "      <td>27.09</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.02</td>\n",
       "      <td>7.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>20.44</td>\n",
       "      <td>2.37</td>\n",
       "      <td>13.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>0.10</td>\n",
       "      <td>26.66</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.11</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>19.58</td>\n",
       "      <td>2.39</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>0.11</td>\n",
       "      <td>26.13</td>\n",
       "      <td>10.06</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.99</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.81</td>\n",
       "      <td>18.27</td>\n",
       "      <td>2.52</td>\n",
       "      <td>13.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>0.09</td>\n",
       "      <td>25.97</td>\n",
       "      <td>10.80</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.23</td>\n",
       "      <td>9.55</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.64</td>\n",
       "      <td>17.42</td>\n",
       "      <td>2.48</td>\n",
       "      <td>13.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>0.09</td>\n",
       "      <td>24.31</td>\n",
       "      <td>12.72</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.47</td>\n",
       "      <td>10.06</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.32</td>\n",
       "      <td>16.32</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>0.09</td>\n",
       "      <td>24.93</td>\n",
       "      <td>11.74</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.44</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>15.27</td>\n",
       "      <td>2.46</td>\n",
       "      <td>13.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>0.06</td>\n",
       "      <td>25.22</td>\n",
       "      <td>11.64</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.41</td>\n",
       "      <td>11.72</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>15.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>13.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Altro   Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                       text   0.08  27.73   9.04    1.97     0.14     2.07   \n",
       "1          proofreading_text   0.09  27.16   8.81    1.98     0.12     2.01   \n",
       "2                   lex_text   0.07  27.09   8.87    1.84     0.12     2.02   \n",
       "3           connectives_text   0.10  26.66   9.34    1.85     0.12     2.11   \n",
       "4           expressions_text   0.11  26.13  10.06    2.02     0.14     2.00   \n",
       "5     sentence_splitter_text   0.09  25.97  10.80    1.97     0.14     2.23   \n",
       "6       nominalizations_text   0.09  24.31  12.72    1.99     0.14     2.47   \n",
       "7                 verbs_text   0.09  24.93  11.74    1.97     0.13     2.44   \n",
       "8  sentence_reorganizer_text   0.06  25.22  11.64    1.97     0.13     2.41   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0      7.51     1.64         0.0     10.17         20.40         2.27   \n",
       "1      7.55     1.61         0.0      9.98         20.33         2.31   \n",
       "2      7.61     1.62         0.0     10.01         20.44         2.37   \n",
       "3      8.12     1.68         0.0      9.99         19.58         2.39   \n",
       "4      8.99     1.30         0.0      9.81         18.27         2.52   \n",
       "5      9.55     1.26         0.0      9.64         17.42         2.48   \n",
       "6     10.06     1.53         0.0      9.32         16.32         2.47   \n",
       "7     11.26     2.25         0.0      9.07         15.27         2.46   \n",
       "8     11.72     2.19         0.0      9.00         15.20         2.48   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coordinati  Cong. subordiante  \n",
       "0          12.22           0.0              4.41               0.35  \n",
       "1          13.30           0.0              4.42               0.32  \n",
       "2          13.18           0.0              4.43               0.32  \n",
       "3          13.27           0.0              4.35               0.43  \n",
       "4          13.68           0.0              4.55               0.40  \n",
       "5          13.89           0.0              4.20               0.36  \n",
       "6          13.89           0.0              4.25               0.43  \n",
       "7          13.54           0.0              4.23               0.60  \n",
       "8          13.14           0.0              4.26               0.57  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':              TEXT,\n",
    "    'Altro':               round((df['n_other'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi':                round((df['n_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Verbi':               round((df['n_verbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Numeri':              round((df['n_number'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Simboli':             round((df['n_symbols'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Avverbi':             round((df['n_adverbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Articoli':            round((df['n_articles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Pronomi':             round((df['n_pronouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Particelle':          round((df['n_particles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Agettivi':            round((df['n_adjectives'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Preposizioni':        round((df['n_prepositions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi propri':         round((df['n_proper_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Punteggiatura':       round((df['n_punctuations'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Interiezioni':        round((df['n_interjections'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. coordinati':    round((df['n_coordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. subordiante':   round((df['n_subordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>1447</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>1442</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>1441</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>1514</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>1391</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>1505</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>1885</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>1962</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>1965</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Verbi attivi  Verbi passivi\n",
       "0                       text          1447            376\n",
       "1          proofreading_text          1442            365\n",
       "2                   lex_text          1441            365\n",
       "3           connectives_text          1514            367\n",
       "4           expressions_text          1391            381\n",
       "5     sentence_splitter_text          1505            463\n",
       "6       nominalizations_text          1885            419\n",
       "7                 verbs_text          1962            162\n",
       "8  sentence_reorganizer_text          1965            158"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   df['n_active_verbs'].sum(),\n",
    "    'Verbi passivi':  df['n_passive_verbs'].sum()\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>80.29</td>\n",
       "      <td>19.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>81.11</td>\n",
       "      <td>18.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>81.10</td>\n",
       "      <td>18.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>81.84</td>\n",
       "      <td>18.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>78.75</td>\n",
       "      <td>21.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>76.76</td>\n",
       "      <td>23.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>84.07</td>\n",
       "      <td>15.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>93.04</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>93.26</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Verbi attivi  Verbi passivi\n",
       "0                       text         80.29          19.71\n",
       "1          proofreading_text         81.11          18.89\n",
       "2                   lex_text         81.10          18.90\n",
       "3           connectives_text         81.84          18.16\n",
       "4           expressions_text         78.75          21.25\n",
       "5     sentence_splitter_text         76.76          23.24\n",
       "6       nominalizations_text         84.07          15.93\n",
       "7                 verbs_text         93.04           6.96\n",
       "8  sentence_reorganizer_text         93.26           6.74"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   round((df['n_active_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "    'Verbi passivi':  round((df['n_passive_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>13368</td>\n",
       "      <td>11130</td>\n",
       "      <td>2302</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>13402</td>\n",
       "      <td>11156</td>\n",
       "      <td>2305</td>\n",
       "      <td>2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>13343</td>\n",
       "      <td>11109</td>\n",
       "      <td>2293</td>\n",
       "      <td>2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>13360</td>\n",
       "      <td>11190</td>\n",
       "      <td>2207</td>\n",
       "      <td>2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>11900</td>\n",
       "      <td>9950</td>\n",
       "      <td>1988</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>12296</td>\n",
       "      <td>10319</td>\n",
       "      <td>2014</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>12357</td>\n",
       "      <td>10451</td>\n",
       "      <td>1953</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>12542</td>\n",
       "      <td>10598</td>\n",
       "      <td>1989</td>\n",
       "      <td>1626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>12657</td>\n",
       "      <td>10693</td>\n",
       "      <td>2008</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ALL     FO    AU    AD\n",
       "0                       text  13368  11130  2302  2125\n",
       "1          proofreading_text  13402  11156  2305  2133\n",
       "2                   lex_text  13343  11109  2293  2130\n",
       "3           connectives_text  13360  11190  2207  2071\n",
       "4           expressions_text  11900   9950  1988  1727\n",
       "5     sentence_splitter_text  12296  10319  2014  1709\n",
       "6       nominalizations_text  12357  10451  1953  1645\n",
       "7                 verbs_text  12542  10598  1989  1626\n",
       "8  sentence_reorganizer_text  12657  10693  2008  1631"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'ALL':      df['n_vdb'].sum(),\n",
    "    'FO':       df['n_vdb_fo'].sum(),\n",
    "    'AU':       df['n_vdb_au'].sum(),\n",
    "    'AD':       df['n_vdb_ad'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>70.81</td>\n",
       "      <td>58.75</td>\n",
       "      <td>12.52</td>\n",
       "      <td>10.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>71.10</td>\n",
       "      <td>59.00</td>\n",
       "      <td>12.52</td>\n",
       "      <td>10.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>71.21</td>\n",
       "      <td>59.05</td>\n",
       "      <td>12.58</td>\n",
       "      <td>10.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>72.03</td>\n",
       "      <td>60.29</td>\n",
       "      <td>12.05</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>74.20</td>\n",
       "      <td>62.33</td>\n",
       "      <td>12.20</td>\n",
       "      <td>10.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>74.89</td>\n",
       "      <td>63.07</td>\n",
       "      <td>12.17</td>\n",
       "      <td>9.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>76.30</td>\n",
       "      <td>64.99</td>\n",
       "      <td>11.74</td>\n",
       "      <td>9.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>76.99</td>\n",
       "      <td>65.62</td>\n",
       "      <td>11.79</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>77.24</td>\n",
       "      <td>65.76</td>\n",
       "      <td>11.87</td>\n",
       "      <td>9.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ALL     FO     AU     AD\n",
       "0                       text  70.81  58.75  12.52  10.85\n",
       "1          proofreading_text  71.10  59.00  12.52  10.94\n",
       "2                   lex_text  71.21  59.05  12.58  10.96\n",
       "3           connectives_text  72.03  60.29  12.05  10.58\n",
       "4           expressions_text  74.20  62.33  12.20  10.12\n",
       "5     sentence_splitter_text  74.89  63.07  12.17   9.77\n",
       "6       nominalizations_text  76.30  64.99  11.74   9.54\n",
       "7                 verbs_text  76.99  65.62  11.79   9.35\n",
       "8  sentence_reorganizer_text  77.24  65.76  11.87   9.32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus': TEXT,\n",
    "    'ALL':    round((df['n_vdb'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'FO':     round((df['n_vdb_fo'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AU':     round((df['n_vdb_au'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AD':     round((df['n_vdb_ad'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>difficult_connectives</th>\n",
       "      <th>latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  difficult_connectives  latinisms\n",
       "0                       text                    233          0\n",
       "1          proofreading_text                    241          0\n",
       "2                   lex_text                    241          0\n",
       "3           connectives_text                     29          0\n",
       "4           expressions_text                     47          0\n",
       "5     sentence_splitter_text                     46          0\n",
       "6       nominalizations_text                     46          0\n",
       "7                 verbs_text                     53          0\n",
       "8  sentence_reorganizer_text                     52          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'difficult_connectives':  df['n_difficult_connectives'].sum(),\n",
    "    'latinisms':              df['n_latinisms'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>unique_difficult_connectives</th>\n",
       "      <th>unique_latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  unique_difficult_connectives  unique_latinisms\n",
       "0                       text                            96                 0\n",
       "1          proofreading_text                            96                 0\n",
       "2                   lex_text                            96                 0\n",
       "3           connectives_text                            15                 0\n",
       "4           expressions_text                            23                 0\n",
       "5     sentence_splitter_text                            26                 0\n",
       "6       nominalizations_text                            27                 0\n",
       "7                 verbs_text                            28                 0\n",
       "8  sentence_reorganizer_text                            27                 0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'unique_difficult_connectives': len(merge_sets([set(j['difficult_connectives']) for j in raw_data[TEXT]])),\n",
    "    'unique_latinisms':       len(merge_sets([set(j['latinisms']) for j in raw_data[TEXT]])),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ttr</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>flesch_vacca</th>\n",
       "      <th>lexical_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>64.91</td>\n",
       "      <td>42.71</td>\n",
       "      <td>17.83</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>64.48</td>\n",
       "      <td>43.48</td>\n",
       "      <td>19.19</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>64.46</td>\n",
       "      <td>43.47</td>\n",
       "      <td>19.36</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>64.85</td>\n",
       "      <td>43.61</td>\n",
       "      <td>19.71</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>66.23</td>\n",
       "      <td>45.39</td>\n",
       "      <td>23.64</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>66.11</td>\n",
       "      <td>49.65</td>\n",
       "      <td>30.29</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>66.62</td>\n",
       "      <td>49.94</td>\n",
       "      <td>30.53</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>65.28</td>\n",
       "      <td>49.34</td>\n",
       "      <td>30.49</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>64.25</td>\n",
       "      <td>48.88</td>\n",
       "      <td>30.13</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ttr  gulpease_index  flesch_vacca  \\\n",
       "0                       text  64.91           42.71         17.83   \n",
       "1          proofreading_text  64.48           43.48         19.19   \n",
       "2                   lex_text  64.46           43.47         19.36   \n",
       "3           connectives_text  64.85           43.61         19.71   \n",
       "4           expressions_text  66.23           45.39         23.64   \n",
       "5     sentence_splitter_text  66.11           49.65         30.29   \n",
       "6       nominalizations_text  66.62           49.94         30.53   \n",
       "7                 verbs_text  65.28           49.34         30.49   \n",
       "8  sentence_reorganizer_text  64.25           48.88         30.13   \n",
       "\n",
       "   lexical_density  \n",
       "0             0.56  \n",
       "1             0.55  \n",
       "2             0.55  \n",
       "3             0.56  \n",
       "4             0.56  \n",
       "5             0.57  \n",
       "6             0.57  \n",
       "7             0.56  \n",
       "8             0.56  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':             TEXT,\n",
    "    'ttr':                round(df['ttr'].mean(), 2),\n",
    "    'gulpease_index':     round(df['gulpease'].mean(), 2),\n",
    "    'flesch_vacca':       round(df['flesch_vacca'].mean(), 2),\n",
    "    'lexical_density':    round(df['lexical_density'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>99.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>99.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>99.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>98.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>98.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>98.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>97.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  semantic_similarity\n",
       "0          original vs proofreading_text                99.63\n",
       "1                   original vs lex_text                99.51\n",
       "2           original vs connectives_text                99.49\n",
       "3           original vs expressions_text                98.57\n",
       "4     original vs sentence_splitter_text                98.45\n",
       "5       original vs nominalizations_text                98.25\n",
       "6                 original vs verbs_text                97.88\n",
       "7  original vs sentence_reorganizer_text                97.80"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':               f'original vs {TEXT}',\n",
    "    'semantic_similarity':  round(df['semantic_similarity'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>%_added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "      <th>%_deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>1663</td>\n",
       "      <td>285</td>\n",
       "      <td>160</td>\n",
       "      <td>56.14</td>\n",
       "      <td>321</td>\n",
       "      <td>190</td>\n",
       "      <td>59.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>2282</td>\n",
       "      <td>344</td>\n",
       "      <td>177</td>\n",
       "      <td>51.45</td>\n",
       "      <td>447</td>\n",
       "      <td>256</td>\n",
       "      <td>57.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>5625</td>\n",
       "      <td>692</td>\n",
       "      <td>495</td>\n",
       "      <td>71.53</td>\n",
       "      <td>889</td>\n",
       "      <td>580</td>\n",
       "      <td>65.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>29177</td>\n",
       "      <td>2011</td>\n",
       "      <td>1599</td>\n",
       "      <td>79.51</td>\n",
       "      <td>3247</td>\n",
       "      <td>2266</td>\n",
       "      <td>69.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>31705</td>\n",
       "      <td>2405</td>\n",
       "      <td>1962</td>\n",
       "      <td>81.58</td>\n",
       "      <td>3330</td>\n",
       "      <td>2324</td>\n",
       "      <td>69.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>34631</td>\n",
       "      <td>2872</td>\n",
       "      <td>2314</td>\n",
       "      <td>80.57</td>\n",
       "      <td>3780</td>\n",
       "      <td>2588</td>\n",
       "      <td>68.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>38864</td>\n",
       "      <td>3176</td>\n",
       "      <td>2591</td>\n",
       "      <td>81.58</td>\n",
       "      <td>4127</td>\n",
       "      <td>2891</td>\n",
       "      <td>70.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>41118</td>\n",
       "      <td>3198</td>\n",
       "      <td>2631</td>\n",
       "      <td>82.27</td>\n",
       "      <td>4145</td>\n",
       "      <td>2909</td>\n",
       "      <td>70.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading_text          1663           285   \n",
       "1                   original vs lex_text          2282           344   \n",
       "2           original vs connectives_text          5625           692   \n",
       "3           original vs expressions_text         29177          2011   \n",
       "4     original vs sentence_splitter_text         31705          2405   \n",
       "5       original vs nominalizations_text         34631          2872   \n",
       "6                 original vs verbs_text         38864          3176   \n",
       "7  original vs sentence_reorganizer_text         41118          3198   \n",
       "\n",
       "   added_vdb_tokens  %_added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \\\n",
       "0               160               56.14             321                 190   \n",
       "1               177               51.45             447                 256   \n",
       "2               495               71.53             889                 580   \n",
       "3              1599               79.51            3247                2266   \n",
       "4              1962               81.58            3330                2324   \n",
       "5              2314               80.57            3780                2588   \n",
       "6              2591               81.58            4127                2891   \n",
       "7              2631               82.27            4145                2909   \n",
       "\n",
       "   %_deleted_vdb_tokens  \n",
       "0                 59.19  \n",
       "1                 57.27  \n",
       "2                 65.24  \n",
       "3                 69.79  \n",
       "4                 69.79  \n",
       "5                 68.47  \n",
       "6                 70.05  \n",
       "7                 70.18  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':                 f'original vs {TEXT}',\n",
    "    'editdistance':           df['editdistance'].sum(),\n",
    "    'added_tokens':           df['n_added_tokens'].sum(),\n",
    "    'added_vdb_tokens':       df['n_added_vdb_tokens'].sum(),\n",
    "    '%_added_vdb_tokens':     round(df['n_added_vdb_tokens'].sum() / df['n_added_tokens'].sum() * 100, 2),\n",
    "    'deleted_tokens':         df['n_deleted_tokens'].sum(),\n",
    "    'deleted_vdb_tokens':     df['n_deleted_vdb_tokens'].sum(),\n",
    "    '%_deleted_vdb_tokens':   round(df['n_deleted_vdb_tokens'].sum() / df['n_deleted_tokens'].sum() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>6.07</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.95</td>\n",
       "      <td>6.58</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>23.76</td>\n",
       "      <td>14.60</td>\n",
       "      <td>11.95</td>\n",
       "      <td>20.67</td>\n",
       "      <td>13.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>26.57</td>\n",
       "      <td>17.05</td>\n",
       "      <td>14.30</td>\n",
       "      <td>20.86</td>\n",
       "      <td>13.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>30.01</td>\n",
       "      <td>21.04</td>\n",
       "      <td>17.55</td>\n",
       "      <td>24.58</td>\n",
       "      <td>16.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>35.55</td>\n",
       "      <td>23.53</td>\n",
       "      <td>19.80</td>\n",
       "      <td>27.00</td>\n",
       "      <td>18.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>38.47</td>\n",
       "      <td>23.51</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.75</td>\n",
       "      <td>18.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading_text          1.66          1.93   \n",
       "1                   original vs lex_text          2.43          2.41   \n",
       "2           original vs connectives_text          6.07          5.36   \n",
       "3           original vs expressions_text         23.76         14.60   \n",
       "4     original vs sentence_splitter_text         26.57         17.05   \n",
       "5       original vs nominalizations_text         30.01         21.04   \n",
       "6                 original vs verbs_text         35.55         23.53   \n",
       "7  original vs sentence_reorganizer_text         38.47         23.51   \n",
       "\n",
       "   added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \n",
       "0              1.18            2.37                1.23  \n",
       "1              1.39            3.38                1.73  \n",
       "2              3.95            6.58                4.05  \n",
       "3             11.95           20.67               13.72  \n",
       "4             14.30           20.86               13.95  \n",
       "5             17.55           24.58               16.14  \n",
       "6             19.80           27.00               18.15  \n",
       "7             19.99           26.75               18.04  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':             f'original vs {TEXT}',\n",
    "    'editdistance':       round((df['editdistance'] / pd.concat([metrics_dfs['text']['n_chars'], df['n_chars']], axis=1).max(axis=1)).mean() * 100, 2),\n",
    "    'added_tokens':       round((df['n_added_tokens'] / df['n_tokens']).mean() * 100, 2),\n",
    "    'added_vdb_tokens':   round((df['n_added_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_tokens':     round((df['n_deleted_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_vdb_tokens': round((df['n_deleted_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
