{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr9yWJNLIx6_"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tSDf1n7iIJo_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sets(sets):\n",
    "  merged = set()\n",
    "  for s in sets:\n",
    "    merged = merged.union(s)\n",
    "  return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvcgTTzMtJre"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTS = ['text', 'proofreading_text', 'lex_text', 'connectives_text', 'expressions_text', 'sentence_splitter_text', 'nominalizations_text', 'verbs_text', 'sentence_reorganizer_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1716393383660,
     "user": {
      "displayName": "Marco Russodivito",
      "userId": "05013084347772678948"
     },
     "user_tz": -120
    },
    "id": "hiRDCeoejAQB",
    "outputId": "cc48f935-f71a-4b58-e4a6-a7d43e084826"
   },
   "outputs": [],
   "source": [
    "metrics_dfs = {TEXT:[] for TEXT in TEXTS}\n",
    "raw_data = {TEXT:[] for TEXT in TEXTS}\n",
    "\n",
    "for TEXT in TEXTS:\n",
    "    metrics_dfs[TEXT] = pd.read_csv(f'./metrics/corpus_test/{TEXT}_metrics.csv')\n",
    "    raw_data[TEXT] = json.load(open(f'./metrics/corpus_test/{TEXT}_raw_data.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens (con punteg.)</th>\n",
       "      <th>Caratteri</th>\n",
       "      <th>Caratteri (con punt)</th>\n",
       "      <th>Sillabe</th>\n",
       "      <th>Frasi</th>\n",
       "      <th>Types</th>\n",
       "      <th>Lemmi</th>\n",
       "      <th>Tokens per frase</th>\n",
       "      <th>Tokens per paragrafo</th>\n",
       "      <th>Frasi per paragrafo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>13720</td>\n",
       "      <td>15447</td>\n",
       "      <td>80844</td>\n",
       "      <td>82571</td>\n",
       "      <td>33612</td>\n",
       "      <td>490</td>\n",
       "      <td>3455</td>\n",
       "      <td>2559</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>240.701754</td>\n",
       "      <td>8.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>13752</td>\n",
       "      <td>15648</td>\n",
       "      <td>80850</td>\n",
       "      <td>82746</td>\n",
       "      <td>33647</td>\n",
       "      <td>503</td>\n",
       "      <td>3427</td>\n",
       "      <td>2537</td>\n",
       "      <td>27.339960</td>\n",
       "      <td>241.263158</td>\n",
       "      <td>8.824561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>13729</td>\n",
       "      <td>15620</td>\n",
       "      <td>80705</td>\n",
       "      <td>82596</td>\n",
       "      <td>33549</td>\n",
       "      <td>504</td>\n",
       "      <td>3415</td>\n",
       "      <td>2526</td>\n",
       "      <td>27.240079</td>\n",
       "      <td>240.859649</td>\n",
       "      <td>8.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>13671</td>\n",
       "      <td>15562</td>\n",
       "      <td>80402</td>\n",
       "      <td>82293</td>\n",
       "      <td>33411</td>\n",
       "      <td>504</td>\n",
       "      <td>3422</td>\n",
       "      <td>2529</td>\n",
       "      <td>27.125000</td>\n",
       "      <td>239.842105</td>\n",
       "      <td>8.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>13208</td>\n",
       "      <td>15077</td>\n",
       "      <td>77672</td>\n",
       "      <td>79541</td>\n",
       "      <td>32293</td>\n",
       "      <td>505</td>\n",
       "      <td>3345</td>\n",
       "      <td>2473</td>\n",
       "      <td>26.154455</td>\n",
       "      <td>231.719298</td>\n",
       "      <td>8.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>13531</td>\n",
       "      <td>15478</td>\n",
       "      <td>79747</td>\n",
       "      <td>81695</td>\n",
       "      <td>33138</td>\n",
       "      <td>706</td>\n",
       "      <td>3371</td>\n",
       "      <td>2491</td>\n",
       "      <td>19.165722</td>\n",
       "      <td>237.385965</td>\n",
       "      <td>12.385965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>13471</td>\n",
       "      <td>15419</td>\n",
       "      <td>79188</td>\n",
       "      <td>81137</td>\n",
       "      <td>32984</td>\n",
       "      <td>707</td>\n",
       "      <td>3410</td>\n",
       "      <td>2507</td>\n",
       "      <td>19.053748</td>\n",
       "      <td>236.333333</td>\n",
       "      <td>12.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>13433</td>\n",
       "      <td>15391</td>\n",
       "      <td>78978</td>\n",
       "      <td>80937</td>\n",
       "      <td>32835</td>\n",
       "      <td>707</td>\n",
       "      <td>3415</td>\n",
       "      <td>2509</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>235.666667</td>\n",
       "      <td>12.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>13422</td>\n",
       "      <td>15350</td>\n",
       "      <td>78880</td>\n",
       "      <td>80809</td>\n",
       "      <td>32795</td>\n",
       "      <td>707</td>\n",
       "      <td>3402</td>\n",
       "      <td>2499</td>\n",
       "      <td>18.984441</td>\n",
       "      <td>235.473684</td>\n",
       "      <td>12.403509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Tokens  Tokens (con punteg.)  Caratteri  \\\n",
       "0                       text   13720                 15447      80844   \n",
       "1          proofreading_text   13752                 15648      80850   \n",
       "2                   lex_text   13729                 15620      80705   \n",
       "3           connectives_text   13671                 15562      80402   \n",
       "4           expressions_text   13208                 15077      77672   \n",
       "5     sentence_splitter_text   13531                 15478      79747   \n",
       "6       nominalizations_text   13471                 15419      79188   \n",
       "7                 verbs_text   13433                 15391      78978   \n",
       "8  sentence_reorganizer_text   13422                 15350      78880   \n",
       "\n",
       "   Caratteri (con punt)  Sillabe  Frasi  Types  Lemmi  Tokens per frase  \\\n",
       "0                 82571    33612    490   3455   2559         28.000000   \n",
       "1                 82746    33647    503   3427   2537         27.339960   \n",
       "2                 82596    33549    504   3415   2526         27.240079   \n",
       "3                 82293    33411    504   3422   2529         27.125000   \n",
       "4                 79541    32293    505   3345   2473         26.154455   \n",
       "5                 81695    33138    706   3371   2491         19.165722   \n",
       "6                 81137    32984    707   3410   2507         19.053748   \n",
       "7                 80937    32835    707   3415   2509         19.000000   \n",
       "8                 80809    32795    707   3402   2499         18.984441   \n",
       "\n",
       "   Tokens per paragrafo  Frasi per paragrafo  \n",
       "0            240.701754             8.596491  \n",
       "1            241.263158             8.824561  \n",
       "2            240.859649             8.842105  \n",
       "3            239.842105             8.842105  \n",
       "4            231.719298             8.859649  \n",
       "5            237.385965            12.385965  \n",
       "6            236.333333            12.403509  \n",
       "7            235.666667            12.403509  \n",
       "8            235.473684            12.403509  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':               TEXT,\n",
    "    'Tokens':               df['n_tokens'].sum(),\n",
    "    'Tokens (con punteg.)': df['n_tokens_all'].sum(),\n",
    "    'Caratteri':            df[f'n_chars'].sum(),\n",
    "    'Caratteri (con punt)': df['n_chars_all'].sum(),\n",
    "    'Sillabe':              df['n_syllables'].sum(),\n",
    "    'Frasi':                df['n_sentences'].sum(),\n",
    "    'Types':                len(merge_sets([set(j['tokens']) for j in raw_data[TEXT]])),\n",
    "    'Lemmi':                len(merge_sets([set(j['lemmas']) for j in raw_data[TEXT]])),\n",
    "    'Tokens per frase':     df['n_tokens'].sum() / df['n_sentences'].sum(),\n",
    "    'Tokens per paragrafo': df['n_tokens'].sum() / df.shape[0],\n",
    "    'Frasi per paragrafo':  df['n_sentences'].sum() / df.shape[0],\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coord.</th>\n",
       "      <th>Cong. sub.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>10</td>\n",
       "      <td>4247</td>\n",
       "      <td>1346</td>\n",
       "      <td>233</td>\n",
       "      <td>15</td>\n",
       "      <td>350</td>\n",
       "      <td>1312</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>1743</td>\n",
       "      <td>3194</td>\n",
       "      <td>325</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>652</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>8</td>\n",
       "      <td>4267</td>\n",
       "      <td>1334</td>\n",
       "      <td>245</td>\n",
       "      <td>15</td>\n",
       "      <td>352</td>\n",
       "      <td>1309</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1744</td>\n",
       "      <td>3207</td>\n",
       "      <td>320</td>\n",
       "      <td>1877</td>\n",
       "      <td>0</td>\n",
       "      <td>661</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>8</td>\n",
       "      <td>4252</td>\n",
       "      <td>1335</td>\n",
       "      <td>243</td>\n",
       "      <td>15</td>\n",
       "      <td>352</td>\n",
       "      <td>1308</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>1740</td>\n",
       "      <td>3204</td>\n",
       "      <td>319</td>\n",
       "      <td>1873</td>\n",
       "      <td>0</td>\n",
       "      <td>661</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>8</td>\n",
       "      <td>4202</td>\n",
       "      <td>1358</td>\n",
       "      <td>243</td>\n",
       "      <td>15</td>\n",
       "      <td>351</td>\n",
       "      <td>1331</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>1738</td>\n",
       "      <td>3142</td>\n",
       "      <td>321</td>\n",
       "      <td>1873</td>\n",
       "      <td>0</td>\n",
       "      <td>662</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>8</td>\n",
       "      <td>4055</td>\n",
       "      <td>1336</td>\n",
       "      <td>244</td>\n",
       "      <td>15</td>\n",
       "      <td>326</td>\n",
       "      <td>1331</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>1683</td>\n",
       "      <td>2953</td>\n",
       "      <td>319</td>\n",
       "      <td>1851</td>\n",
       "      <td>0</td>\n",
       "      <td>657</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>8</td>\n",
       "      <td>4139</td>\n",
       "      <td>1490</td>\n",
       "      <td>245</td>\n",
       "      <td>15</td>\n",
       "      <td>353</td>\n",
       "      <td>1447</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>1685</td>\n",
       "      <td>2924</td>\n",
       "      <td>324</td>\n",
       "      <td>1929</td>\n",
       "      <td>0</td>\n",
       "      <td>614</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>8</td>\n",
       "      <td>3953</td>\n",
       "      <td>1700</td>\n",
       "      <td>245</td>\n",
       "      <td>15</td>\n",
       "      <td>368</td>\n",
       "      <td>1488</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>1663</td>\n",
       "      <td>2785</td>\n",
       "      <td>323</td>\n",
       "      <td>1930</td>\n",
       "      <td>0</td>\n",
       "      <td>614</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>8</td>\n",
       "      <td>3995</td>\n",
       "      <td>1581</td>\n",
       "      <td>247</td>\n",
       "      <td>15</td>\n",
       "      <td>365</td>\n",
       "      <td>1573</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1653</td>\n",
       "      <td>2735</td>\n",
       "      <td>345</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>617</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>8</td>\n",
       "      <td>3989</td>\n",
       "      <td>1579</td>\n",
       "      <td>245</td>\n",
       "      <td>15</td>\n",
       "      <td>364</td>\n",
       "      <td>1585</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>1647</td>\n",
       "      <td>2730</td>\n",
       "      <td>350</td>\n",
       "      <td>1910</td>\n",
       "      <td>0</td>\n",
       "      <td>615</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Altro  Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                       text     10  4247   1346     233       15      350   \n",
       "1          proofreading_text      8  4267   1334     245       15      352   \n",
       "2                   lex_text      8  4252   1335     243       15      352   \n",
       "3           connectives_text      8  4202   1358     243       15      351   \n",
       "4           expressions_text      8  4055   1336     244       15      326   \n",
       "5     sentence_splitter_text      8  4139   1490     245       15      353   \n",
       "6       nominalizations_text      8  3953   1700     245       15      368   \n",
       "7                 verbs_text      8  3995   1581     247       15      365   \n",
       "8  sentence_reorganizer_text      8  3989   1579     245       15      364   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0      1312      248           0      1743          3194          325   \n",
       "1      1309      247           0      1744          3207          320   \n",
       "2      1308      248           0      1740          3204          319   \n",
       "3      1331      249           0      1738          3142          321   \n",
       "4      1331      231           0      1683          2953          319   \n",
       "5      1447      245           0      1685          2924          324   \n",
       "6      1488      257           0      1663          2785          323   \n",
       "7      1573      247           0      1653          2735          345   \n",
       "8      1585      245           0      1647          2730          350   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coord.  Cong. sub.  \n",
       "0           1710             0           652          62  \n",
       "1           1877             0           661          62  \n",
       "2           1873             0           661          62  \n",
       "3           1873             0           662          69  \n",
       "4           1851             0           657          68  \n",
       "5           1929             0           614          60  \n",
       "6           1930             0           614          70  \n",
       "7           1940             0           617          70  \n",
       "8           1910             0           615          68  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':        TEXT,\n",
    "    'Altro':         df['n_other'].sum(),\n",
    "    'Nomi':          df['n_nouns'].sum(),\n",
    "    'Verbi':         df['n_verbs'].sum(),\n",
    "    'Numeri':        df['n_number'].sum(),\n",
    "    'Simboli':       df['n_symbols'].sum(),\n",
    "    'Avverbi':       df['n_adverbs'].sum(),\n",
    "    'Articoli':      df['n_articles'].sum(),\n",
    "    'Pronomi':       df['n_pronouns'].sum(),\n",
    "    'Particelle':    df['n_particles'].sum(),\n",
    "    'Agettivi':      df['n_adjectives'].sum(),\n",
    "    'Preposizioni':  df['n_prepositions'].sum(),\n",
    "    'Nomi propri':   df['n_proper_nouns'].sum(),\n",
    "    'Punteggiatura': df['n_punctuations'].sum(),\n",
    "    'Interiezioni':  df['n_interjections'].sum(),\n",
    "    'Cong. coord.':  df['n_coordinating_conjunctions'].sum(),\n",
    "    'Cong. sub.':    df['n_subordinating_conjunctions'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Altro</th>\n",
       "      <th>Nomi</th>\n",
       "      <th>Verbi</th>\n",
       "      <th>Numeri</th>\n",
       "      <th>Simboli</th>\n",
       "      <th>Avverbi</th>\n",
       "      <th>Articoli</th>\n",
       "      <th>Pronomi</th>\n",
       "      <th>Particelle</th>\n",
       "      <th>Agettivi</th>\n",
       "      <th>Preposizioni</th>\n",
       "      <th>Nomi propri</th>\n",
       "      <th>Punteggiatura</th>\n",
       "      <th>Interiezioni</th>\n",
       "      <th>Cong. coordinati</th>\n",
       "      <th>Cong. subordiante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>0.09</td>\n",
       "      <td>28.52</td>\n",
       "      <td>8.61</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.08</td>\n",
       "      <td>8.10</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.55</td>\n",
       "      <td>21.42</td>\n",
       "      <td>1.97</td>\n",
       "      <td>10.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>28.18</td>\n",
       "      <td>8.37</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.06</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.41</td>\n",
       "      <td>21.20</td>\n",
       "      <td>1.90</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>28.15</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.07</td>\n",
       "      <td>7.93</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.41</td>\n",
       "      <td>21.21</td>\n",
       "      <td>1.90</td>\n",
       "      <td>11.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>27.81</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.05</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.45</td>\n",
       "      <td>20.70</td>\n",
       "      <td>1.92</td>\n",
       "      <td>12.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>27.59</td>\n",
       "      <td>8.98</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.02</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.43</td>\n",
       "      <td>19.96</td>\n",
       "      <td>1.97</td>\n",
       "      <td>12.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>0.07</td>\n",
       "      <td>27.41</td>\n",
       "      <td>9.95</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.19</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.04</td>\n",
       "      <td>19.06</td>\n",
       "      <td>1.92</td>\n",
       "      <td>12.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>25.80</td>\n",
       "      <td>12.06</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.29</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.92</td>\n",
       "      <td>17.74</td>\n",
       "      <td>1.90</td>\n",
       "      <td>12.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>26.17</td>\n",
       "      <td>11.24</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.28</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>17.26</td>\n",
       "      <td>2.08</td>\n",
       "      <td>12.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>0.08</td>\n",
       "      <td>26.26</td>\n",
       "      <td>11.24</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2.27</td>\n",
       "      <td>10.63</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.88</td>\n",
       "      <td>17.25</td>\n",
       "      <td>2.06</td>\n",
       "      <td>12.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Altro   Nomi  Verbi  Numeri  Simboli  Avverbi  \\\n",
       "0                       text   0.09  28.52   8.61    1.38     0.07     2.08   \n",
       "1          proofreading_text   0.08  28.18   8.37    1.42     0.07     2.06   \n",
       "2                   lex_text   0.08  28.15   8.38    1.42     0.07     2.07   \n",
       "3           connectives_text   0.08  27.81   8.67    1.43     0.07     2.05   \n",
       "4           expressions_text   0.08  27.59   8.98    1.47     0.07     2.02   \n",
       "5     sentence_splitter_text   0.07  27.41   9.95    1.41     0.07     2.19   \n",
       "6       nominalizations_text   0.08  25.80  12.06    1.42     0.07     2.29   \n",
       "7                 verbs_text   0.08  26.17  11.24    1.42     0.07     2.28   \n",
       "8  sentence_reorganizer_text   0.08  26.26  11.24    1.41     0.07     2.27   \n",
       "\n",
       "   Articoli  Pronomi  Particelle  Agettivi  Preposizioni  Nomi propri  \\\n",
       "0      8.10     1.76         0.0     10.55         21.42         1.97   \n",
       "1      7.92     1.70         0.0     10.41         21.20         1.90   \n",
       "2      7.93     1.70         0.0     10.41         21.21         1.90   \n",
       "3      8.27     1.72         0.0     10.45         20.70         1.92   \n",
       "4      8.54     1.68         0.0     10.43         19.96         1.97   \n",
       "5      9.23     1.67         0.0     10.04         19.06         1.92   \n",
       "6      9.55     2.00         0.0      9.92         17.74         1.90   \n",
       "7     10.49     1.86         0.0      9.87         17.26         2.08   \n",
       "8     10.63     1.84         0.0      9.88         17.25         2.06   \n",
       "\n",
       "   Punteggiatura  Interiezioni  Cong. coordinati  Cong. subordiante  \n",
       "0          10.77           0.0              4.28               0.40  \n",
       "1          11.97           0.0              4.33               0.39  \n",
       "2          11.96           0.0              4.34               0.39  \n",
       "3          12.01           0.0              4.36               0.46  \n",
       "4          12.31           0.0              4.46               0.46  \n",
       "5          12.59           0.0              3.99               0.40  \n",
       "6          12.62           0.0              4.01               0.56  \n",
       "7          12.60           0.0              4.04               0.56  \n",
       "8          12.41           0.0              4.03               0.55  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':              TEXT,\n",
    "    'Altro':               round((df['n_other'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi':                round((df['n_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Verbi':               round((df['n_verbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Numeri':              round((df['n_number'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Simboli':             round((df['n_symbols'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Avverbi':             round((df['n_adverbs'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Articoli':            round((df['n_articles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Pronomi':             round((df['n_pronouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Particelle':          round((df['n_particles'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Agettivi':            round((df['n_adjectives'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Preposizioni':        round((df['n_prepositions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Nomi propri':         round((df['n_proper_nouns'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Punteggiatura':       round((df['n_punctuations'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Interiezioni':        round((df['n_interjections'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. coordinati':    round((df['n_coordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "    'Cong. subordiante':   round((df['n_subordinating_conjunctions'] / df['n_tokens_all']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>1077</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>1063</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>1064</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>1087</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>1071</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>1169</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>1369</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>1348</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>1346</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Verbi attivi  Verbi passivi\n",
       "0                       text          1077            269\n",
       "1          proofreading_text          1063            271\n",
       "2                   lex_text          1064            271\n",
       "3           connectives_text          1087            271\n",
       "4           expressions_text          1071            265\n",
       "5     sentence_splitter_text          1169            321\n",
       "6       nominalizations_text          1369            331\n",
       "7                 verbs_text          1348            233\n",
       "8  sentence_reorganizer_text          1346            233"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   df['n_active_verbs'].sum(),\n",
    "    'Verbi passivi':  df['n_passive_verbs'].sum()\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Verbi attivi</th>\n",
       "      <th>Verbi passivi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>84.17</td>\n",
       "      <td>15.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>83.54</td>\n",
       "      <td>16.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>83.54</td>\n",
       "      <td>16.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>83.50</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>84.27</td>\n",
       "      <td>15.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>80.61</td>\n",
       "      <td>19.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>82.26</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>87.86</td>\n",
       "      <td>12.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>87.79</td>\n",
       "      <td>12.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  Verbi attivi  Verbi passivi\n",
       "0                       text         84.17          15.83\n",
       "1          proofreading_text         83.54          16.46\n",
       "2                   lex_text         83.54          16.46\n",
       "3           connectives_text         83.50          16.50\n",
       "4           expressions_text         84.27          15.73\n",
       "5     sentence_splitter_text         80.61          19.39\n",
       "6       nominalizations_text         82.26          17.74\n",
       "7                 verbs_text         87.86          12.14\n",
       "8  sentence_reorganizer_text         87.79          12.21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':         TEXT,\n",
    "    'Verbi attivi':   round((df['n_active_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "    'Verbi passivi':  round((df['n_passive_verbs'] / df['n_verbs']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>9965</td>\n",
       "      <td>8186</td>\n",
       "      <td>1877</td>\n",
       "      <td>1563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>9983</td>\n",
       "      <td>8198</td>\n",
       "      <td>1882</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>9970</td>\n",
       "      <td>8185</td>\n",
       "      <td>1882</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>9974</td>\n",
       "      <td>8205</td>\n",
       "      <td>1851</td>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>9665</td>\n",
       "      <td>7960</td>\n",
       "      <td>1784</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>9974</td>\n",
       "      <td>8249</td>\n",
       "      <td>1807</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>10068</td>\n",
       "      <td>8375</td>\n",
       "      <td>1776</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>10011</td>\n",
       "      <td>8306</td>\n",
       "      <td>1790</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>10015</td>\n",
       "      <td>8312</td>\n",
       "      <td>1789</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ALL    FO    AU    AD\n",
       "0                       text   9965  8186  1877  1563\n",
       "1          proofreading_text   9983  8198  1882  1578\n",
       "2                   lex_text   9970  8185  1882  1579\n",
       "3           connectives_text   9974  8205  1851  1564\n",
       "4           expressions_text   9665  7960  1784  1491\n",
       "5     sentence_splitter_text   9974  8249  1807  1471\n",
       "6       nominalizations_text  10068  8375  1776  1454\n",
       "7                 verbs_text  10011  8306  1790  1419\n",
       "8  sentence_reorganizer_text  10015  8312  1789  1416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'ALL':      df['n_vdb'].sum(),\n",
    "    'FO':       df['n_vdb_fo'].sum(),\n",
    "    'AU':       df['n_vdb_au'].sum(),\n",
    "    'AD':       df['n_vdb_ad'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ALL</th>\n",
       "      <th>FO</th>\n",
       "      <th>AU</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>72.32</td>\n",
       "      <td>59.02</td>\n",
       "      <td>13.72</td>\n",
       "      <td>11.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>72.28</td>\n",
       "      <td>58.95</td>\n",
       "      <td>13.74</td>\n",
       "      <td>11.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>72.30</td>\n",
       "      <td>58.95</td>\n",
       "      <td>13.76</td>\n",
       "      <td>11.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>72.84</td>\n",
       "      <td>59.68</td>\n",
       "      <td>13.48</td>\n",
       "      <td>11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>73.21</td>\n",
       "      <td>60.30</td>\n",
       "      <td>13.20</td>\n",
       "      <td>11.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>74.03</td>\n",
       "      <td>61.33</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>75.63</td>\n",
       "      <td>63.22</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>75.60</td>\n",
       "      <td>63.11</td>\n",
       "      <td>12.79</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>75.72</td>\n",
       "      <td>63.25</td>\n",
       "      <td>12.78</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ALL     FO     AU     AD\n",
       "0                       text  72.32  59.02  13.72  11.46\n",
       "1          proofreading_text  72.28  58.95  13.74  11.63\n",
       "2                   lex_text  72.30  58.95  13.76  11.64\n",
       "3           connectives_text  72.84  59.68  13.48  11.68\n",
       "4           expressions_text  73.21  60.30  13.20  11.46\n",
       "5     sentence_splitter_text  74.03  61.33  12.99  10.99\n",
       "6       nominalizations_text  75.63  63.22  12.70  10.70\n",
       "7                 verbs_text  75.60  63.11  12.79  10.40\n",
       "8  sentence_reorganizer_text  75.72  63.25  12.78  10.40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus': TEXT,\n",
    "    'ALL':    round((df['n_vdb'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'FO':     round((df['n_vdb_fo'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AU':     round((df['n_vdb_au'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "    'AD':     round((df['n_vdb_ad'] / df['n_tokens']).fillna(0).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>difficult_connectives</th>\n",
       "      <th>latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  difficult_connectives  latinisms\n",
       "0                       text                    166          0\n",
       "1          proofreading_text                    167          0\n",
       "2                   lex_text                    167          0\n",
       "3           connectives_text                    129          0\n",
       "4           expressions_text                    109          0\n",
       "5     sentence_splitter_text                     97          0\n",
       "6       nominalizations_text                     94          0\n",
       "7                 verbs_text                     94          0\n",
       "8  sentence_reorganizer_text                     94          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'difficult_connectives':  df['n_difficult_connectives'].sum(),\n",
    "    'latinisms':              df['n_latinisms'].sum(),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>unique_difficult_connectives</th>\n",
       "      <th>unique_latinisms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus  unique_difficult_connectives  unique_latinisms\n",
       "0                       text                            77                 0\n",
       "1          proofreading_text                            78                 0\n",
       "2                   lex_text                            78                 0\n",
       "3           connectives_text                            63                 0\n",
       "4           expressions_text                            57                 0\n",
       "5     sentence_splitter_text                            54                 0\n",
       "6       nominalizations_text                            54                 0\n",
       "7                 verbs_text                            54                 0\n",
       "8  sentence_reorganizer_text                            54                 0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':   TEXT,\n",
    "    'unique_difficult_connectives': len(merge_sets([set(j['difficult_connectives']) for j in raw_data[TEXT]])),\n",
    "    'unique_latinisms':       len(merge_sets([set(j['latinisms']) for j in raw_data[TEXT]])),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ttr</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>flesch_vacca</th>\n",
       "      <th>lexical_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>66.49</td>\n",
       "      <td>41.37</td>\n",
       "      <td>16.56</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proofreading_text</td>\n",
       "      <td>66.04</td>\n",
       "      <td>41.73</td>\n",
       "      <td>17.11</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lex_text</td>\n",
       "      <td>66.03</td>\n",
       "      <td>41.72</td>\n",
       "      <td>17.20</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connectives_text</td>\n",
       "      <td>66.27</td>\n",
       "      <td>41.78</td>\n",
       "      <td>17.55</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expressions_text</td>\n",
       "      <td>66.74</td>\n",
       "      <td>42.21</td>\n",
       "      <td>18.43</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_splitter_text</td>\n",
       "      <td>66.42</td>\n",
       "      <td>46.86</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nominalizations_text</td>\n",
       "      <td>66.94</td>\n",
       "      <td>47.19</td>\n",
       "      <td>28.21</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>verbs_text</td>\n",
       "      <td>66.14</td>\n",
       "      <td>47.28</td>\n",
       "      <td>28.52</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentence_reorganizer_text</td>\n",
       "      <td>65.95</td>\n",
       "      <td>47.37</td>\n",
       "      <td>28.93</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Corpus    ttr  gulpease_index  flesch_vacca  \\\n",
       "0                       text  66.49           41.37         16.56   \n",
       "1          proofreading_text  66.04           41.73         17.11   \n",
       "2                   lex_text  66.03           41.72         17.20   \n",
       "3           connectives_text  66.27           41.78         17.55   \n",
       "4           expressions_text  66.74           42.21         18.43   \n",
       "5     sentence_splitter_text  66.42           46.86         28.00   \n",
       "6       nominalizations_text  66.94           47.19         28.21   \n",
       "7                 verbs_text  66.14           47.28         28.52   \n",
       "8  sentence_reorganizer_text  65.95           47.37         28.93   \n",
       "\n",
       "   lexical_density  \n",
       "0             0.56  \n",
       "1             0.56  \n",
       "2             0.56  \n",
       "3             0.56  \n",
       "4             0.56  \n",
       "5             0.57  \n",
       "6             0.57  \n",
       "7             0.57  \n",
       "8             0.57  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  d.append({\n",
    "    'Corpus':             TEXT,\n",
    "    'ttr':                round(df['ttr'].mean(), 2),\n",
    "    'gulpease_index':     round(df['gulpease'].mean(), 2),\n",
    "    'flesch_vacca':       round(df['flesch_vacca'].mean(), 2),\n",
    "    'lexical_density':    round(df['lexical_density'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>99.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>99.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>99.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>98.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>98.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>98.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>98.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  semantic_similarity\n",
       "0          original vs proofreading_text                99.75\n",
       "1                   original vs lex_text                99.68\n",
       "2           original vs connectives_text                99.53\n",
       "3           original vs expressions_text                99.14\n",
       "4     original vs sentence_splitter_text                98.90\n",
       "5       original vs nominalizations_text                98.75\n",
       "6                 original vs verbs_text                98.51\n",
       "7  original vs sentence_reorganizer_text                98.47"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':               f'original vs {TEXT}',\n",
    "    'semantic_similarity':  round(df['semantic_similarity'].mean(), 2)\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>%_added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "      <th>%_deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>471</td>\n",
       "      <td>110</td>\n",
       "      <td>54</td>\n",
       "      <td>49.09</td>\n",
       "      <td>143</td>\n",
       "      <td>73</td>\n",
       "      <td>51.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>761</td>\n",
       "      <td>147</td>\n",
       "      <td>72</td>\n",
       "      <td>48.98</td>\n",
       "      <td>197</td>\n",
       "      <td>100</td>\n",
       "      <td>50.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>1716</td>\n",
       "      <td>288</td>\n",
       "      <td>197</td>\n",
       "      <td>68.40</td>\n",
       "      <td>363</td>\n",
       "      <td>216</td>\n",
       "      <td>59.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>6650</td>\n",
       "      <td>579</td>\n",
       "      <td>452</td>\n",
       "      <td>78.07</td>\n",
       "      <td>913</td>\n",
       "      <td>635</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>10426</td>\n",
       "      <td>990</td>\n",
       "      <td>823</td>\n",
       "      <td>83.13</td>\n",
       "      <td>1057</td>\n",
       "      <td>755</td>\n",
       "      <td>71.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>12051</td>\n",
       "      <td>1280</td>\n",
       "      <td>1043</td>\n",
       "      <td>81.48</td>\n",
       "      <td>1328</td>\n",
       "      <td>901</td>\n",
       "      <td>67.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>14333</td>\n",
       "      <td>1402</td>\n",
       "      <td>1145</td>\n",
       "      <td>81.67</td>\n",
       "      <td>1543</td>\n",
       "      <td>1086</td>\n",
       "      <td>70.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>15287</td>\n",
       "      <td>1404</td>\n",
       "      <td>1147</td>\n",
       "      <td>81.70</td>\n",
       "      <td>1570</td>\n",
       "      <td>1100</td>\n",
       "      <td>70.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading_text           471           110   \n",
       "1                   original vs lex_text           761           147   \n",
       "2           original vs connectives_text          1716           288   \n",
       "3           original vs expressions_text          6650           579   \n",
       "4     original vs sentence_splitter_text         10426           990   \n",
       "5       original vs nominalizations_text         12051          1280   \n",
       "6                 original vs verbs_text         14333          1402   \n",
       "7  original vs sentence_reorganizer_text         15287          1404   \n",
       "\n",
       "   added_vdb_tokens  %_added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \\\n",
       "0                54               49.09             143                  73   \n",
       "1                72               48.98             197                 100   \n",
       "2               197               68.40             363                 216   \n",
       "3               452               78.07             913                 635   \n",
       "4               823               83.13            1057                 755   \n",
       "5              1043               81.48            1328                 901   \n",
       "6              1145               81.67            1543                1086   \n",
       "7              1147               81.70            1570                1100   \n",
       "\n",
       "   %_deleted_vdb_tokens  \n",
       "0                 51.05  \n",
       "1                 50.76  \n",
       "2                 59.50  \n",
       "3                 69.55  \n",
       "4                 71.43  \n",
       "5                 67.85  \n",
       "6                 70.38  \n",
       "7                 70.06  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':                 f'original vs {TEXT}',\n",
    "    'editdistance':           df['editdistance'].sum(),\n",
    "    'added_tokens':           df['n_added_tokens'].sum(),\n",
    "    'added_vdb_tokens':       df['n_added_vdb_tokens'].sum(),\n",
    "    '%_added_vdb_tokens':     round(df['n_added_vdb_tokens'].sum() / df['n_added_tokens'].sum() * 100, 2),\n",
    "    'deleted_tokens':         df['n_deleted_tokens'].sum(),\n",
    "    'deleted_vdb_tokens':     df['n_deleted_vdb_tokens'].sum(),\n",
    "    '%_deleted_vdb_tokens':   round(df['n_deleted_vdb_tokens'].sum() / df['n_deleted_tokens'].sum() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>editdistance</th>\n",
       "      <th>added_tokens</th>\n",
       "      <th>added_vdb_tokens</th>\n",
       "      <th>deleted_tokens</th>\n",
       "      <th>deleted_vdb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original vs proofreading_text</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original vs lex_text</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original vs connectives_text</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original vs expressions_text</td>\n",
       "      <td>9.65</td>\n",
       "      <td>6.98</td>\n",
       "      <td>5.65</td>\n",
       "      <td>9.34</td>\n",
       "      <td>6.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original vs sentence_splitter_text</td>\n",
       "      <td>14.84</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.22</td>\n",
       "      <td>9.90</td>\n",
       "      <td>7.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original vs nominalizations_text</td>\n",
       "      <td>17.90</td>\n",
       "      <td>14.24</td>\n",
       "      <td>12.08</td>\n",
       "      <td>13.00</td>\n",
       "      <td>8.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original vs verbs_text</td>\n",
       "      <td>21.26</td>\n",
       "      <td>15.43</td>\n",
       "      <td>13.04</td>\n",
       "      <td>15.10</td>\n",
       "      <td>10.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original vs sentence_reorganizer_text</td>\n",
       "      <td>22.84</td>\n",
       "      <td>15.39</td>\n",
       "      <td>13.02</td>\n",
       "      <td>15.25</td>\n",
       "      <td>10.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Corpus  editdistance  added_tokens  \\\n",
       "0          original vs proofreading_text          0.74          0.95   \n",
       "1                   original vs lex_text          1.02          1.18   \n",
       "2           original vs connectives_text          3.14          3.49   \n",
       "3           original vs expressions_text          9.65          6.98   \n",
       "4     original vs sentence_splitter_text         14.84         10.75   \n",
       "5       original vs nominalizations_text         17.90         14.24   \n",
       "6                 original vs verbs_text         21.26         15.43   \n",
       "7  original vs sentence_reorganizer_text         22.84         15.39   \n",
       "\n",
       "   added_vdb_tokens  deleted_tokens  deleted_vdb_tokens  \n",
       "0              0.51            1.22                0.67  \n",
       "1              0.64            1.56                0.86  \n",
       "2              2.69            3.95                2.65  \n",
       "3              5.65            9.34                6.73  \n",
       "4              9.22            9.90                7.27  \n",
       "5             12.08           13.00                8.85  \n",
       "6             13.04           15.10               10.55  \n",
       "7             13.02           15.25               10.60  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = []\n",
    "for TEXT, df in metrics_dfs.items():\n",
    "  if TEXT == 'text':\n",
    "    continue\n",
    "  d.append({\n",
    "    'Corpus':             f'original vs {TEXT}',\n",
    "    'editdistance':       round((df['editdistance'] / pd.concat([metrics_dfs['text']['n_chars'], df['n_chars']], axis=1).max(axis=1)).mean() * 100, 2),\n",
    "    'added_tokens':       round((df['n_added_tokens'] / df['n_tokens']).mean() * 100, 2),\n",
    "    'added_vdb_tokens':   round((df['n_added_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_tokens':     round((df['n_deleted_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "    'deleted_vdb_tokens': round((df['n_deleted_vdb_tokens'] /  df['n_tokens']).mean() * 100, 2),\n",
    "  })\n",
    "\n",
    "pd.DataFrame(d).head(20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
